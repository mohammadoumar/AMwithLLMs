{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.4808461368083954,
      "learning_rate": 8.92857142857143e-06,
      "loss": 0.697,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.278053879737854,
      "learning_rate": 1.785714285714286e-05,
      "loss": 0.0792,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.31250059604644775,
      "learning_rate": 2.6785714285714288e-05,
      "loss": 0.0429,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.17752127349376678,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.0363,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.19551226496696472,
      "learning_rate": 4.464285714285715e-05,
      "loss": 0.043,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.18346455693244934,
      "learning_rate": 4.999222955002041e-05,
      "loss": 0.041,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.07595375925302505,
      "learning_rate": 4.990486745229364e-05,
      "loss": 0.0271,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.2687309682369232,
      "learning_rate": 4.972077065562821e-05,
      "loss": 0.0373,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.2097471058368683,
      "learning_rate": 4.944065422298262e-05,
      "loss": 0.0417,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.3236357569694519,
      "learning_rate": 4.90656061737503e-05,
      "loss": 0.0263,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.1198398694396019,
      "learning_rate": 4.8597083257709194e-05,
      "loss": 0.0267,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.0643555298447609,
      "learning_rate": 4.803690529676019e-05,
      "loss": 0.0246,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.11359672993421555,
      "learning_rate": 4.738724811643252e-05,
      "loss": 0.0207,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.10889346152544022,
      "learning_rate": 4.665063509461097e-05,
      "loss": 0.0257,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.196819469332695,
      "learning_rate": 4.582992736031123e-05,
      "loss": 0.019,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 0.13672077655792236,
      "learning_rate": 4.4928312680573064e-05,
      "loss": 0.0185,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.48280057311058044,
      "learning_rate": 4.394929307863633e-05,
      "loss": 0.024,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.26396644115448,
      "learning_rate": 4.2896671231492966e-05,
      "loss": 0.028,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.038700640201568604,
      "learning_rate": 4.1774535699649255e-05,
      "loss": 0.0175,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.29369428753852844,
      "learning_rate": 4.058724504646834e-05,
      "loss": 0.0197,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.08069237321615219,
      "learning_rate": 3.933941090877615e-05,
      "loss": 0.0154,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.2126525342464447,
      "learning_rate": 3.803588008448745e-05,
      "loss": 0.0218,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.12603558599948883,
      "learning_rate": 3.668171570682655e-05,
      "loss": 0.017,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.10927754640579224,
      "learning_rate": 3.5282177578265296e-05,
      "loss": 0.0094,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.031280267983675,
      "learning_rate": 3.3842701740564534e-05,
      "loss": 0.0145,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.24476273357868195,
      "learning_rate": 3.2368879360272606e-05,
      "loss": 0.0122,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.19303059577941895,
      "learning_rate": 3.0866435011692885e-05,
      "loss": 0.0099,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 0.21224237978458405,
      "learning_rate": 2.9341204441673266e-05,
      "loss": 0.0109,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.09612743556499481,
      "learning_rate": 2.7799111902582696e-05,
      "loss": 0.0087,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.34977030754089355,
      "learning_rate": 2.624614714151743e-05,
      "loss": 0.0169,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 0.26187843084335327,
      "learning_rate": 2.4688342135114627e-05,
      "loss": 0.0111,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.18273860216140747,
      "learning_rate": 2.3131747660339394e-05,
      "loss": 0.0113,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.1712840050458908,
      "learning_rate": 2.158240979224817e-05,
      "loss": 0.0151,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.14525394141674042,
      "learning_rate": 2.0046346420015067e-05,
      "loss": 0.0084,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.07693243026733398,
      "learning_rate": 1.852952387243698e-05,
      "loss": 0.0057,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.03404752537608147,
      "learning_rate": 1.7037833743707892e-05,
      "loss": 0.0031,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.10124624520540237,
      "learning_rate": 1.557707000947487e-05,
      "loss": 0.0071,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.09160270541906357,
      "learning_rate": 1.4152906522061048e-05,
      "loss": 0.0061,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.005102951545268297,
      "learning_rate": 1.2770874972267777e-05,
      "loss": 0.005,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 0.19908353686332703,
      "learning_rate": 1.1436343403356017e-05,
      "loss": 0.0034,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.054314617067575455,
      "learning_rate": 1.0154495360662464e-05,
      "loss": 0.0053,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.08964268118143082,
      "learning_rate": 8.930309757836517e-06,
      "loss": 0.0039,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.09114113450050354,
      "learning_rate": 7.768541537901325e-06,
      "loss": 0.0056,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.13893191516399384,
      "learning_rate": 6.673703204254347e-06,
      "loss": 0.0026,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.17261910438537598,
      "learning_rate": 5.650047293344315e-06,
      "loss": 0.0059,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.027632221579551697,
      "learning_rate": 4.701549857103588e-06,
      "loss": 0.0019,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.01712673343718052,
      "learning_rate": 3.831895019292897e-06,
      "loss": 0.0011,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.10307791829109192,
      "learning_rate": 3.044460665744284e-06,
      "loss": 0.0012,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.003824812825769186,
      "learning_rate": 2.3423053240837515e-06,
      "loss": 0.0013,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.004722334444522858,
      "learning_rate": 1.7281562838948966e-06,
      "loss": 0.0008,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.028141319751739502,
      "learning_rate": 1.204399003466941e-06,
      "loss": 0.0009,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.24671593308448792,
      "learning_rate": 7.730678442730538e-07,
      "loss": 0.0019,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.043101344257593155,
      "learning_rate": 4.358381691677932e-07,
      "loss": 0.0014,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.015292084775865078,
      "learning_rate": 1.9401983499569842e-07,
      "loss": 0.0024,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.03272208198904991,
      "learning_rate": 4.855210488670381e-08,
      "loss": 0.0031,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.09819695353507996,
      "learning_rate": 0.0,
      "loss": 0.0011,
      "step": 560
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2378258418958336e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
