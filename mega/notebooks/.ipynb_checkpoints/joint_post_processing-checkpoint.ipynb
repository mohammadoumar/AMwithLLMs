{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "692363ef-bedd-4b2b-854e-983bcf7f6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import inspect\n",
    "import argparse\n",
    "import subprocess\n",
    "\n",
    "# sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c9624b-1eb0-4377-9328-6732fe7a2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path(os.path.dirname(os.path.abspath(\"__file__\"))).as_posix()\n",
    "joint_dir = Path(current_dir).parent.absolute().as_posix()\n",
    "# parent_dir = Path(cdcp_dir).parent.absolute().as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbdef0b6-1950-4f1e-948d-34684718b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/coling_2025/joint/notebooks'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38dd22f5-4e12-4ae9-997c-c05bf62debb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/coling_2025/joint'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3e93dda-c2a7-4814-84fe-0d88b4a059ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "TASK = \"mega\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feb16562-0aec-4e2a-86b0-467efaa5214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(joint_dir, \"finetuned_models\", f\"\"\"{TASK}_{BASE_MODEL.split(\"/\")[1]}\"\"\")\n",
    "NB_EPOCHS = 5\n",
    "test_set = \"mix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96bb9767-c681-42c9-870a-2a7f4117d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/scratch/umushtaq/coling_2025/joint/finetuned_models/mega_Meta-Llama-3.1-8B-Instruct-bnb-4bit'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc35ef83-1e22-4489-9a0e-18fec4fd7ac2",
   "metadata": {},
   "source": [
    "### AbstRCT Dataset post-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fa0846f-3603-498a-ba85-af1ffb7ae418",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, f\"\"\"abstRCT_{TASK}_results_{NB_EPOCHS}_{test_set}.pickle\"\"\"), 'rb') as fh:\n",
    "    \n",
    "    results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8ea1d-f780-4c74-af96-947f55dddbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cebb780c-32f6-4c31-af65-2426f3749c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite_acc(component_type):\n",
    "\n",
    "    if component_type == \"Claim\":\n",
    "        return \"Premise\"\n",
    "    elif component_type == \"Premise\":\n",
    "        return \"Claim\"\n",
    "\n",
    "def harmonize_preds_acc(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite_acc(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds \n",
    "\n",
    "def post_process_acc(results):\n",
    "\n",
    "    grounds = results[\"ground_truths\"]\n",
    "    preds = results[\"predictions\"]\n",
    "    \n",
    "    grounds = [json.loads(x)[\"component_types\"] for x in grounds]  \n",
    "    \n",
    "    preds = [x[\"content\"] for x in preds]    \n",
    "    preds = [json.loads(x)[\"component_types\"] for x in preds]\n",
    "    \n",
    "    for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "    \n",
    "        if len(x) != len(y):\n",
    "            \n",
    "            preds[i] = harmonize_preds_acc(x, y)\n",
    "            \n",
    "    task_preds = [item for row in preds for item in row]\n",
    "    task_grounds = [item for row in grounds for item in row]\n",
    "\n",
    "    return task_grounds, task_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97f3c51f-7274-4736-99cc-fa4086f6f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_grounds, task_preds = post_process_acc(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20c5852c-28be-464b-9541-c956393aa667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim      0.934     0.939     0.936       212\n",
      "     Premise      0.967     0.965     0.966       397\n",
      "\n",
      "    accuracy                          0.956       609\n",
      "   macro avg      0.951     0.952     0.951       609\n",
      "weighted avg      0.956     0.956     0.956       609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(task_grounds, task_preds, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9813e85-bcbc-40f5-8c6f-368575e04291",
   "metadata": {},
   "source": [
    "MEGA ABSTRCT NEO:\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.938     0.915     0.927       248\n",
    "     Premise      0.953     0.966     0.960       443\n",
    "\n",
    "    accuracy                          0.948       691\n",
    "   macro avg      0.946     0.941     0.943       691\n",
    "weighted avg      0.948     0.948     0.948       691\n",
    "\n",
    "GLA:\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.910     0.895     0.902       191\n",
    "     Premise      0.953     0.960     0.957       424\n",
    "\n",
    "    accuracy                          0.940       615\n",
    "   macro avg      0.931     0.928     0.929       615\n",
    "weighted avg      0.940     0.940     0.940       615\n",
    "\n",
    "MIX:\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.934     0.939     0.936       212\n",
    "     Premise      0.967     0.965     0.966       397\n",
    "\n",
    "    accuracy                          0.956       609\n",
    "   macro avg      0.951     0.952     0.951       609\n",
    "weighted avg      0.956     0.956     0.956       609"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ca22a-6ff2-40e1-a73b-25f9163ec2be",
   "metadata": {},
   "source": [
    "### CDCP Post-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a317f8f8-810f-443e-a307-32afdb3c3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, f\"\"\"CDCP_{TASK}_results_{NB_EPOCHS}.pickle\"\"\"), 'rb') as fh:\n",
    "    \n",
    "    results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0373c6ae-225d-4588-a335-206663f44d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite_acc(component_type):\n",
    "\n",
    "    if component_type == \"fact\":\n",
    "        return \"value\"\n",
    "    elif component_type == \"value\":\n",
    "        return \"policy\"\n",
    "    elif component_type == \"policy\":\n",
    "        return \"value\"\n",
    "    elif component_type == \"testimony\":\n",
    "        return \"fact\"\n",
    "    elif component_type == \"reference\":\n",
    "        return \"policy\"\n",
    "\n",
    "def harmonize_preds_acc(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite_acc(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds \n",
    "\n",
    "def post_process_acc(results):\n",
    "\n",
    "    grounds = results[\"ground_truths\"]\n",
    "    preds = results[\"predictions\"]\n",
    "    \n",
    "    grounds = [json.loads(x)[\"component_types\"] for x in grounds]  \n",
    "    \n",
    "    preds = [x[\"content\"] for x in preds]    \n",
    "    preds = [json.loads(x)[\"component_types\"] for x in preds]\n",
    "    \n",
    "    for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "    \n",
    "        if len(x) != len(y):\n",
    "            \n",
    "            preds[i] = harmonize_preds_acc(x, y)\n",
    "            \n",
    "    task_preds = [item for row in preds for item in row]\n",
    "    task_grounds = [item for row in grounds for item in row]\n",
    "\n",
    "    return task_grounds, task_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "268d20c6-b2cb-4b83-a814-355122b77566",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_grounds, task_preds = post_process_acc(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8be8ae37-ce72-4d8b-8d1f-f0a813136c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fact      0.615     0.750     0.676       132\n",
      "      policy      0.890     0.902     0.896       153\n",
      "   reference      0.500     1.000     0.667         1\n",
      "   testimony      0.932     0.836     0.881       244\n",
      "       value      0.859     0.847     0.853       496\n",
      "\n",
      "    accuracy                          0.840      1026\n",
      "   macro avg      0.759     0.867     0.795      1026\n",
      "weighted avg      0.849     0.840     0.843      1026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(task_grounds, task_preds, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c50e623-d07c-465f-90fc-5099c0629ee0",
   "metadata": {},
   "source": [
    "MEGA CDCP:\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "        fact      0.615     0.750     0.676       132\n",
    "      policy      0.890     0.902     0.896       153\n",
    "   reference      0.500     1.000     0.667         1\n",
    "   testimony      0.932     0.836     0.881       244\n",
    "       value      0.859     0.847     0.853       496\n",
    "\n",
    "    accuracy                          0.840      1026\n",
    "   macro avg      0.759     0.867     0.795      1026\n",
    "weighted avg      0.849     0.840     0.843      1026\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971af13a-295e-4d1c-9e82-641f61a95c13",
   "metadata": {},
   "source": [
    "### PE Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a13bf71-9779-4c9b-b885-334b9be34c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, f\"\"\"PE_{TASK}_results_{NB_EPOCHS}.pickle\"\"\"), 'rb') as fh:\n",
    "    \n",
    "    results = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0000cbea-06e5-4373-862e-a6e9ca86d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite_acc(component_type):\n",
    "\n",
    "    if component_type == \"Premise\":\n",
    "        return \"Claim\"\n",
    "    elif component_type == \"Claim\":\n",
    "        return \"Premise\"\n",
    "    elif component_type == \"MajorClaim\":\n",
    "        return \"Claim\"\n",
    "\n",
    "def harmonize_preds_acc(grounds, preds):\n",
    "\n",
    "    l1, l2 = len(preds), len(grounds)\n",
    "    if l1 < l2:\n",
    "        diff = l2 - l1\n",
    "        preds = preds + [opposite_acc(x) for x in grounds[l1:]]\n",
    "    else:\n",
    "        preds = preds[:l2]\n",
    "        \n",
    "    return preds \n",
    "\n",
    "def post_process_acc(results):\n",
    "\n",
    "    grounds = results[\"ground_truths\"]\n",
    "    preds = results[\"predictions\"]\n",
    "    \n",
    "    grounds = [json.loads(x)[\"component_types\"] for x in grounds]  \n",
    "    \n",
    "    preds = [x[\"content\"] for x in preds]    \n",
    "    preds = [json.loads(x)[\"component_types\"] for x in preds]\n",
    "    \n",
    "    for i,(x,y) in enumerate(zip(grounds, preds)):\n",
    "    \n",
    "        if len(x) != len(y):\n",
    "            \n",
    "            preds[i] = harmonize_preds_acc(x, y)\n",
    "            \n",
    "    task_preds = [item for row in preds for item in row]\n",
    "    task_grounds = [item for row in grounds for item in row]\n",
    "\n",
    "    return task_grounds, task_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b24245e-8795-4e84-ace7-f0c466abddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_grounds, task_preds = post_process_acc(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c554aca8-321f-45c6-ade8-9a1b643a2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim      0.771     0.795     0.783       283\n",
      "  MajorClaim      0.986     0.948     0.967       154\n",
      "     Premise      0.922     0.919     0.920       724\n",
      "\n",
      "    accuracy                          0.892      1161\n",
      "   macro avg      0.893     0.887     0.890      1161\n",
      "weighted avg      0.894     0.892     0.893      1161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(task_grounds, task_preds, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "022e6e35-d2d1-49b9-9aa9-f1478c80eab2",
   "metadata": {},
   "source": [
    "MEGA PE:\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.771     0.795     0.783       283\n",
    "  MajorClaim      0.986     0.948     0.967       154\n",
    "     Premise      0.922     0.919     0.920       724\n",
    "\n",
    "    accuracy                          0.892      1161\n",
    "   macro avg      0.893     0.887     0.890      1161\n",
    "weighted avg      0.894     0.892     0.893      1161"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
