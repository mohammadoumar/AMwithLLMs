{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.984025559105431,
  "eval_steps": 500,
  "global_step": 780,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06389776357827476,
      "grad_norm": 1.1115268468856812,
      "learning_rate": 5.76923076923077e-06,
      "loss": 0.6737,
      "step": 10
    },
    {
      "epoch": 0.12779552715654952,
      "grad_norm": 0.7418141961097717,
      "learning_rate": 1.217948717948718e-05,
      "loss": 0.265,
      "step": 20
    },
    {
      "epoch": 0.19169329073482427,
      "grad_norm": 1.0099375247955322,
      "learning_rate": 1.858974358974359e-05,
      "loss": 0.1664,
      "step": 30
    },
    {
      "epoch": 0.25559105431309903,
      "grad_norm": 0.5966520309448242,
      "learning_rate": 2.5e-05,
      "loss": 0.1476,
      "step": 40
    },
    {
      "epoch": 0.3194888178913738,
      "grad_norm": 0.40868133306503296,
      "learning_rate": 3.141025641025641e-05,
      "loss": 0.1281,
      "step": 50
    },
    {
      "epoch": 0.38338658146964855,
      "grad_norm": 0.7808838486671448,
      "learning_rate": 3.782051282051282e-05,
      "loss": 0.1306,
      "step": 60
    },
    {
      "epoch": 0.4472843450479233,
      "grad_norm": 0.6810480952262878,
      "learning_rate": 4.423076923076923e-05,
      "loss": 0.1208,
      "step": 70
    },
    {
      "epoch": 0.5111821086261981,
      "grad_norm": 0.41644197702407837,
      "learning_rate": 4.999974965737065e-05,
      "loss": 0.1023,
      "step": 80
    },
    {
      "epoch": 0.5750798722044729,
      "grad_norm": 2.529934883117676,
      "learning_rate": 4.996971460796929e-05,
      "loss": 0.1203,
      "step": 90
    },
    {
      "epoch": 0.6389776357827476,
      "grad_norm": 0.5850904583930969,
      "learning_rate": 4.9889679948572974e-05,
      "loss": 0.0981,
      "step": 100
    },
    {
      "epoch": 0.7028753993610224,
      "grad_norm": 0.6075507998466492,
      "learning_rate": 4.9759805941396075e-05,
      "loss": 0.1033,
      "step": 110
    },
    {
      "epoch": 0.7667731629392971,
      "grad_norm": 0.5276853442192078,
      "learning_rate": 4.958035264746893e-05,
      "loss": 0.0948,
      "step": 120
    },
    {
      "epoch": 0.8306709265175719,
      "grad_norm": 0.5172742009162903,
      "learning_rate": 4.935167940588887e-05,
      "loss": 0.0867,
      "step": 130
    },
    {
      "epoch": 0.8945686900958466,
      "grad_norm": 0.5415239930152893,
      "learning_rate": 4.907424411427608e-05,
      "loss": 0.0906,
      "step": 140
    },
    {
      "epoch": 0.9584664536741214,
      "grad_norm": 0.44720831513404846,
      "learning_rate": 4.8748602311874694e-05,
      "loss": 0.0857,
      "step": 150
    },
    {
      "epoch": 1.0223642172523961,
      "grad_norm": 0.7828329801559448,
      "learning_rate": 4.837540606713538e-05,
      "loss": 0.0794,
      "step": 160
    },
    {
      "epoch": 1.0862619808306708,
      "grad_norm": 0.484529584646225,
      "learning_rate": 4.7955402672006854e-05,
      "loss": 0.0647,
      "step": 170
    },
    {
      "epoch": 1.1501597444089458,
      "grad_norm": 0.7341780662536621,
      "learning_rate": 4.748943314555093e-05,
      "loss": 0.0589,
      "step": 180
    },
    {
      "epoch": 1.2140575079872205,
      "grad_norm": 0.34985974431037903,
      "learning_rate": 4.697843054987737e-05,
      "loss": 0.0577,
      "step": 190
    },
    {
      "epoch": 1.2779552715654952,
      "grad_norm": 0.6942656636238098,
      "learning_rate": 4.6423418121770855e-05,
      "loss": 0.0422,
      "step": 200
    },
    {
      "epoch": 1.34185303514377,
      "grad_norm": 0.39961302280426025,
      "learning_rate": 4.58255072237513e-05,
      "loss": 0.0727,
      "step": 210
    },
    {
      "epoch": 1.4057507987220448,
      "grad_norm": 0.28837481141090393,
      "learning_rate": 4.518589511867017e-05,
      "loss": 0.0556,
      "step": 220
    },
    {
      "epoch": 1.4696485623003195,
      "grad_norm": 0.3232872486114502,
      "learning_rate": 4.4505862572299315e-05,
      "loss": 0.0517,
      "step": 230
    },
    {
      "epoch": 1.5335463258785942,
      "grad_norm": 0.5616317987442017,
      "learning_rate": 4.37867712887125e-05,
      "loss": 0.0704,
      "step": 240
    },
    {
      "epoch": 1.5974440894568689,
      "grad_norm": 0.8836203217506409,
      "learning_rate": 4.303006118359537e-05,
      "loss": 0.0606,
      "step": 250
    },
    {
      "epoch": 1.6613418530351438,
      "grad_norm": 0.8283066749572754,
      "learning_rate": 4.223724750094366e-05,
      "loss": 0.0652,
      "step": 260
    },
    {
      "epoch": 1.7252396166134185,
      "grad_norm": 0.8917091488838196,
      "learning_rate": 4.140991777892324e-05,
      "loss": 0.0673,
      "step": 270
    },
    {
      "epoch": 1.7891373801916934,
      "grad_norm": 0.9075408577919006,
      "learning_rate": 4.05497286709676e-05,
      "loss": 0.0657,
      "step": 280
    },
    {
      "epoch": 1.8530351437699681,
      "grad_norm": 0.4963904321193695,
      "learning_rate": 3.965840262847818e-05,
      "loss": 0.0609,
      "step": 290
    },
    {
      "epoch": 1.9169329073482428,
      "grad_norm": 0.6507170796394348,
      "learning_rate": 3.873772445177015e-05,
      "loss": 0.052,
      "step": 300
    },
    {
      "epoch": 1.9808306709265175,
      "grad_norm": 0.5457672476768494,
      "learning_rate": 3.7789537716170256e-05,
      "loss": 0.0639,
      "step": 310
    },
    {
      "epoch": 2.0447284345047922,
      "grad_norm": 0.49946603178977966,
      "learning_rate": 3.681574108042274e-05,
      "loss": 0.0492,
      "step": 320
    },
    {
      "epoch": 2.108626198083067,
      "grad_norm": 0.6316983103752136,
      "learning_rate": 3.5818284484795904e-05,
      "loss": 0.0289,
      "step": 330
    },
    {
      "epoch": 2.1725239616613417,
      "grad_norm": 0.6545922160148621,
      "learning_rate": 3.479916524650188e-05,
      "loss": 0.0215,
      "step": 340
    },
    {
      "epoch": 2.236421725239617,
      "grad_norm": 0.35179415345191956,
      "learning_rate": 3.3760424060248344e-05,
      "loss": 0.025,
      "step": 350
    },
    {
      "epoch": 2.3003194888178915,
      "grad_norm": 0.16251836717128754,
      "learning_rate": 3.270414091193077e-05,
      "loss": 0.0356,
      "step": 360
    },
    {
      "epoch": 2.364217252396166,
      "grad_norm": 0.2893056571483612,
      "learning_rate": 3.163243091364752e-05,
      "loss": 0.0376,
      "step": 370
    },
    {
      "epoch": 2.428115015974441,
      "grad_norm": 0.7162274122238159,
      "learning_rate": 3.054744006837794e-05,
      "loss": 0.0353,
      "step": 380
    },
    {
      "epoch": 2.4920127795527156,
      "grad_norm": 0.43369877338409424,
      "learning_rate": 2.945134097280417e-05,
      "loss": 0.0224,
      "step": 390
    },
    {
      "epoch": 2.5559105431309903,
      "grad_norm": 0.4113951027393341,
      "learning_rate": 2.8346328466881545e-05,
      "loss": 0.0321,
      "step": 400
    },
    {
      "epoch": 2.619808306709265,
      "grad_norm": 0.12380284816026688,
      "learning_rate": 2.7234615238868732e-05,
      "loss": 0.0242,
      "step": 410
    },
    {
      "epoch": 2.68370607028754,
      "grad_norm": 0.8858082890510559,
      "learning_rate": 2.6118427394618357e-05,
      "loss": 0.0294,
      "step": 420
    },
    {
      "epoch": 2.747603833865815,
      "grad_norm": 0.38969337940216064,
      "learning_rate": 2.5e-05,
      "loss": 0.0316,
      "step": 430
    },
    {
      "epoch": 2.8115015974440896,
      "grad_norm": 0.6747575998306274,
      "learning_rate": 2.388157260538165e-05,
      "loss": 0.0324,
      "step": 440
    },
    {
      "epoch": 2.8753993610223643,
      "grad_norm": 0.26992520689964294,
      "learning_rate": 2.2765384761131274e-05,
      "loss": 0.0218,
      "step": 450
    },
    {
      "epoch": 2.939297124600639,
      "grad_norm": 0.30500903725624084,
      "learning_rate": 2.1653671533118468e-05,
      "loss": 0.0256,
      "step": 460
    },
    {
      "epoch": 3.0031948881789137,
      "grad_norm": 0.5019510984420776,
      "learning_rate": 2.054865902719584e-05,
      "loss": 0.0217,
      "step": 470
    },
    {
      "epoch": 3.0670926517571884,
      "grad_norm": 0.03755176439881325,
      "learning_rate": 1.9452559931622067e-05,
      "loss": 0.0077,
      "step": 480
    },
    {
      "epoch": 3.130990415335463,
      "grad_norm": 0.14374081790447235,
      "learning_rate": 1.8367569086352483e-05,
      "loss": 0.0086,
      "step": 490
    },
    {
      "epoch": 3.194888178913738,
      "grad_norm": 0.2421797513961792,
      "learning_rate": 1.7295859088069234e-05,
      "loss": 0.0062,
      "step": 500
    },
    {
      "epoch": 3.258785942492013,
      "grad_norm": 0.11802221834659576,
      "learning_rate": 1.623957593975166e-05,
      "loss": 0.0068,
      "step": 510
    },
    {
      "epoch": 3.3226837060702876,
      "grad_norm": 0.04998632147908211,
      "learning_rate": 1.5200834753498128e-05,
      "loss": 0.009,
      "step": 520
    },
    {
      "epoch": 3.3865814696485623,
      "grad_norm": 0.34399211406707764,
      "learning_rate": 1.4181715515204095e-05,
      "loss": 0.0043,
      "step": 530
    },
    {
      "epoch": 3.450479233226837,
      "grad_norm": 0.10147316008806229,
      "learning_rate": 1.3184258919577269e-05,
      "loss": 0.0048,
      "step": 540
    },
    {
      "epoch": 3.5143769968051117,
      "grad_norm": 0.2513454258441925,
      "learning_rate": 1.2210462283829755e-05,
      "loss": 0.0084,
      "step": 550
    },
    {
      "epoch": 3.5782747603833864,
      "grad_norm": 0.046087026596069336,
      "learning_rate": 1.126227554822985e-05,
      "loss": 0.0093,
      "step": 560
    },
    {
      "epoch": 3.642172523961661,
      "grad_norm": 0.37696221470832825,
      "learning_rate": 1.0341597371521825e-05,
      "loss": 0.0108,
      "step": 570
    },
    {
      "epoch": 3.7060702875399363,
      "grad_norm": 0.11029132455587387,
      "learning_rate": 9.450271329032404e-06,
      "loss": 0.0065,
      "step": 580
    },
    {
      "epoch": 3.769968051118211,
      "grad_norm": 0.5230470299720764,
      "learning_rate": 8.590082221076765e-06,
      "loss": 0.0057,
      "step": 590
    },
    {
      "epoch": 3.8338658146964857,
      "grad_norm": 0.2936871647834778,
      "learning_rate": 7.762752499056358e-06,
      "loss": 0.0039,
      "step": 600
    },
    {
      "epoch": 3.8977635782747604,
      "grad_norm": 0.03025023080408573,
      "learning_rate": 6.969938816404639e-06,
      "loss": 0.0029,
      "step": 610
    },
    {
      "epoch": 3.961661341853035,
      "grad_norm": 0.11841186881065369,
      "learning_rate": 6.2132287112875e-06,
      "loss": 0.0061,
      "step": 620
    },
    {
      "epoch": 4.02555910543131,
      "grad_norm": 0.19017519056797028,
      "learning_rate": 5.494137427700688e-06,
      "loss": 0.0054,
      "step": 630
    },
    {
      "epoch": 4.0894568690095845,
      "grad_norm": 0.08783528208732605,
      "learning_rate": 4.814104881329828e-06,
      "loss": 0.0013,
      "step": 640
    },
    {
      "epoch": 4.15335463258786,
      "grad_norm": 0.005677721928805113,
      "learning_rate": 4.174492776248712e-06,
      "loss": 0.0007,
      "step": 650
    },
    {
      "epoch": 4.217252396166134,
      "grad_norm": 0.05174415186047554,
      "learning_rate": 3.576581878229143e-06,
      "loss": 0.0006,
      "step": 660
    },
    {
      "epoch": 4.281150159744409,
      "grad_norm": 0.25339221954345703,
      "learning_rate": 3.0215694501226384e-06,
      "loss": 0.0019,
      "step": 670
    },
    {
      "epoch": 4.345047923322683,
      "grad_norm": 0.02653208188712597,
      "learning_rate": 2.5105668544490727e-06,
      "loss": 0.0003,
      "step": 680
    },
    {
      "epoch": 4.4089456869009584,
      "grad_norm": 0.7001253962516785,
      "learning_rate": 2.044597327993153e-06,
      "loss": 0.0017,
      "step": 690
    },
    {
      "epoch": 4.472843450479234,
      "grad_norm": 0.020122064277529716,
      "learning_rate": 1.624593932864632e-06,
      "loss": 0.0015,
      "step": 700
    },
    {
      "epoch": 4.536741214057508,
      "grad_norm": 0.013598887249827385,
      "learning_rate": 1.251397688125311e-06,
      "loss": 0.001,
      "step": 710
    },
    {
      "epoch": 4.600638977635783,
      "grad_norm": 0.05953310430049896,
      "learning_rate": 9.257558857239224e-07,
      "loss": 0.0031,
      "step": 720
    },
    {
      "epoch": 4.664536741214057,
      "grad_norm": 0.04980051517486572,
      "learning_rate": 6.483205941111348e-07,
      "loss": 0.0011,
      "step": 730
    },
    {
      "epoch": 4.728434504792332,
      "grad_norm": 0.014214543625712395,
      "learning_rate": 4.1964735253108013e-07,
      "loss": 0.0014,
      "step": 740
    },
    {
      "epoch": 4.792332268370607,
      "grad_norm": 0.08445846289396286,
      "learning_rate": 2.401940586039236e-07,
      "loss": 0.0007,
      "step": 750
    },
    {
      "epoch": 4.856230031948882,
      "grad_norm": 0.12930825352668762,
      "learning_rate": 1.1032005142703195e-07,
      "loss": 0.0004,
      "step": 760
    },
    {
      "epoch": 4.920127795527156,
      "grad_norm": 0.01790817826986313,
      "learning_rate": 3.0285392030710015e-08,
      "loss": 0.0031,
      "step": 770
    },
    {
      "epoch": 4.984025559105431,
      "grad_norm": 0.009390803053975105,
      "learning_rate": 2.5034262935152986e-10,
      "loss": 0.0006,
      "step": 780
    }
  ],
  "logging_steps": 10,
  "max_steps": 780,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0328372805002854e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
