{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.16786645352840424,
      "learning_rate": 8.92857142857143e-06,
      "loss": 0.1637,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.08492232114076614,
      "learning_rate": 1.785714285714286e-05,
      "loss": 0.0218,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.21310076117515564,
      "learning_rate": 2.6785714285714288e-05,
      "loss": 0.033,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.02186529152095318,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.0175,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.10005049407482147,
      "learning_rate": 4.464285714285715e-05,
      "loss": 0.0238,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.058373790234327316,
      "learning_rate": 4.999222955002041e-05,
      "loss": 0.016,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.053690776228904724,
      "learning_rate": 4.990486745229364e-05,
      "loss": 0.0143,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.1403762698173523,
      "learning_rate": 4.972077065562821e-05,
      "loss": 0.0051,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.007396394852548838,
      "learning_rate": 4.944065422298262e-05,
      "loss": 0.0133,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.23965637385845184,
      "learning_rate": 4.90656061737503e-05,
      "loss": 0.0126,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.016706978902220726,
      "learning_rate": 4.8597083257709194e-05,
      "loss": 0.0059,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.002384536201134324,
      "learning_rate": 4.803690529676019e-05,
      "loss": 0.0028,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.008637713268399239,
      "learning_rate": 4.738724811643252e-05,
      "loss": 0.0075,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.059801384806632996,
      "learning_rate": 4.665063509461097e-05,
      "loss": 0.0079,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.1670709103345871,
      "learning_rate": 4.582992736031123e-05,
      "loss": 0.0083,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 0.3734198808670044,
      "learning_rate": 4.4928312680573064e-05,
      "loss": 0.0143,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.1456647515296936,
      "learning_rate": 4.394929307863633e-05,
      "loss": 0.0098,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.016532722860574722,
      "learning_rate": 4.2896671231492966e-05,
      "loss": 0.0079,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.0037190227303653955,
      "learning_rate": 4.1774535699649255e-05,
      "loss": 0.0046,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.07344577461481094,
      "learning_rate": 4.058724504646834e-05,
      "loss": 0.0057,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.004440560936927795,
      "learning_rate": 3.933941090877615e-05,
      "loss": 0.0069,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.12123935669660568,
      "learning_rate": 3.803588008448745e-05,
      "loss": 0.0042,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.006144839338958263,
      "learning_rate": 3.668171570682655e-05,
      "loss": 0.0029,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.02729303017258644,
      "learning_rate": 3.5282177578265296e-05,
      "loss": 0.0016,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.014948152005672455,
      "learning_rate": 3.3842701740564534e-05,
      "loss": 0.0016,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.0014174116076901555,
      "learning_rate": 3.2368879360272606e-05,
      "loss": 0.0002,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.17890843749046326,
      "learning_rate": 3.0866435011692885e-05,
      "loss": 0.0035,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 0.20205022394657135,
      "learning_rate": 2.9341204441673266e-05,
      "loss": 0.0038,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.04249144718050957,
      "learning_rate": 2.7799111902582696e-05,
      "loss": 0.0058,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.14334601163864136,
      "learning_rate": 2.624614714151743e-05,
      "loss": 0.0021,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 0.0011856351047754288,
      "learning_rate": 2.4688342135114627e-05,
      "loss": 0.0017,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.001119904569350183,
      "learning_rate": 2.3131747660339394e-05,
      "loss": 0.0004,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.000438718096120283,
      "learning_rate": 2.158240979224817e-05,
      "loss": 0.0036,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.008977454155683517,
      "learning_rate": 2.0046346420015067e-05,
      "loss": 0.0015,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.013822106644511223,
      "learning_rate": 1.852952387243698e-05,
      "loss": 0.0006,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.003402457572519779,
      "learning_rate": 1.7037833743707892e-05,
      "loss": 0.0004,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.0004377498116809875,
      "learning_rate": 1.557707000947487e-05,
      "loss": 0.0005,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.016659852117300034,
      "learning_rate": 1.4152906522061048e-05,
      "loss": 0.0004,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.004958087112754583,
      "learning_rate": 1.2770874972267777e-05,
      "loss": 0.0001,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 0.017726678401231766,
      "learning_rate": 1.1436343403356017e-05,
      "loss": 0.0012,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.00030049573979340494,
      "learning_rate": 1.0154495360662464e-05,
      "loss": 0.0007,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.00046223701792769134,
      "learning_rate": 8.930309757836517e-06,
      "loss": 0.0006,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.0013953312300145626,
      "learning_rate": 7.768541537901325e-06,
      "loss": 0.0003,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.0003421963774599135,
      "learning_rate": 6.673703204254347e-06,
      "loss": 0.0019,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.00010197039227932692,
      "learning_rate": 5.650047293344315e-06,
      "loss": 0.0001,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.004312627483159304,
      "learning_rate": 4.701549857103588e-06,
      "loss": 0.0001,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.007209047209471464,
      "learning_rate": 3.831895019292897e-06,
      "loss": 0.0005,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.004813511855900288,
      "learning_rate": 3.044460665744284e-06,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.000715108122676611,
      "learning_rate": 2.3423053240837515e-06,
      "loss": 0.0004,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.0006800377159379423,
      "learning_rate": 1.7281562838948966e-06,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.0032247549388557673,
      "learning_rate": 1.204399003466941e-06,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.0021203719079494476,
      "learning_rate": 7.730678442730538e-07,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.004034720826894045,
      "learning_rate": 4.358381691677932e-07,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.00023838708875700831,
      "learning_rate": 1.9401983499569842e-07,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.0003799868281930685,
      "learning_rate": 4.855210488670381e-08,
      "loss": 0.0,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 6.455423863371834e-05,
      "learning_rate": 0.0,
      "loss": 0.0001,
      "step": 560
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.929974171585741e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
