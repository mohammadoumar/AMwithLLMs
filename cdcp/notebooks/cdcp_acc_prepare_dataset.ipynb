{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b092f16-851d-4a47-ae4f-2a85603d6c77",
   "metadata": {},
   "source": [
    "# Prepare dataset (jsonl file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798ef15",
   "metadata": {},
   "source": [
    "- Prepare CDCP datasets for llama factory.\n",
    "\n",
    "- Argument Class Classification (ACC)\n",
    "\n",
    "- We create the data files: `CDCP_acc_train.json`, `CDCP_acc_test.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdfbf4b-663f-41af-85a1-266a48239c9e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872238e4-5235-4176-bd84-4cc384bca8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af75678-bbcc-4cfa-9b81-c9a66d170182",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fccf6a27-07f6-4582-9160-01cd030b47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcp_dataset = load_dataset(\"DFKI-SLT/cdcp\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44fadc88-bba2-4f88-9d00-8b4ffd2153f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'propositions', 'relations'],\n",
       "        num_rows: 580\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'propositions', 'relations'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdcp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9d7c5-fc35-43ac-88e1-4489cc57ea98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "989b8b61-76b8-486a-9b9b-21ab46f66012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_instruction(nr_acs):\n",
    "\n",
    "    results = json.dumps([\"component_type (str)\"] * nr_acs)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length {nr_acs}, in following JSON format: {{\"component_types\": {results}}} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \n",
    "\"\"\"\n",
    "    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6041a1-f9ff-4098-a684-dd51eb92e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a55082-ec6e-40c9-a754-43175e6dbc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tags(text, start_indices, end_indices):\n",
    "\n",
    "    offset = 0\n",
    "\n",
    "    for i, (start_i, end_i) in enumerate(zip(start_indices, end_indices)):\n",
    "            \n",
    "        start_tag = \"<AC\" + str(i+1) + \">\"\n",
    "        end_tag = \"</AC\" + str(i+1) + \">\"\n",
    "        \n",
    "        start_idx = start_i + offset\n",
    "        end_idx = end_i + offset\n",
    "\n",
    "        offset = offset + (len(start_tag)  + len(end_tag))\n",
    "        \n",
    "        text_r = text[start_idx:end_idx]\n",
    "        new_text = start_tag + text_r + end_tag\n",
    "        text = text.replace(text_r, new_text)\n",
    "\n",
    "        question = f\"\"\"### Here is the text: {text}\"\"\"\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfae3867-aa66-44f5-bebc-90b4e4b11dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ac_types(raw_labels):\n",
    "\n",
    "    \n",
    "    class_labels = [\"fact\", \"policy\", \"reference\", \"testimony\", \"value\"]\n",
    "\n",
    "    labels = [class_labels[i] for i in raw_labels]\n",
    "    \n",
    "    return json.dumps({\"component_types\": labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa5d61-2b62-4050-a089-2705a327c556",
   "metadata": {},
   "source": [
    "## Create Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1e9b28-bb55-41ff-a927-372b933574e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_train = []\n",
    "\n",
    "for sample in cdcp_dataset[\"train\"]:\n",
    "\n",
    "    sample_text = sample[\"text\"]\n",
    "    start_l = sample[\"propositions\"][\"start\"]\n",
    "    end_l = sample[\"propositions\"][\"end\"]\n",
    "    raw_labels = sample[\"propositions\"][\"label\"]\n",
    "\n",
    "    instruction = write_instruction(len(raw_labels))\n",
    "    question = insert_tags(sample_text, start_l, end_l)\n",
    "    answer = get_ac_types(raw_labels)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ef4fc0-7cfc-4c4b-b81b-237cbdbc1b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40b355c-2b04-47b3-92d4-d75a191903c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 3, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n', 'input': '### Here is the text: <AC1>State and local court rules sometimes make default judgments much more likely.</AC1><AC2> For example, when a person who allegedly owes a debt is told to come to court on a work day, they may be forced to choose between a default judgment and their job.</AC2><AC3> I urge the CFPB to find practices that involve scheduling hearings at inconvenient times unfair, deceptive, and abusive, or inconsistent with 1692i.</AC3>', 'output': '{\"component_types\": [\"value\", \"value\", \"policy\"]}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 4, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n', 'input': \"### Here is the text: <AC1>There is currently a split between the Ninth and First Circuits as to whether 1692i and other FDCPA provisions apply in garnishment proceedings.</AC1><AC2> In many states, the nominal defendant is the judgment debtor's employer,</AC2><AC3> but the judgment debtor is the real party in interest.</AC3><AC4> To allow consumers to better assert the defenses to and exemptions from garnishment available under state law, the CFPB should issue a rule applying 1692i to garnishment proceedings.</AC4>\", 'output': '{\"component_types\": [\"fact\", \"fact\", \"value\", \"policy\"]}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 4, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n', 'input': \"### Here is the text: <AC1>In many districts where bad check diversion programs exist, there is anecdotal evidence that the companies administering the programs threaten with prosecution individuals who do not come within the state's bad check law</AC1><AC2> for example, checks that bounce due to printing errors, checks for which there were funds available when written but not when presented, and individuals who pay the amount due by other means within grace periods permitted by state law.</AC2><AC3> The CFPB should ensure that bad check diversion programs have a realistic means of ensuring that only individuals realistically subject to prosecution are targeted,</AC3><AC4> and should also require that, in order to qualify for the 1692p safe harbor, diversion programs prohibit misleading communications and misstatements of state bad check law.</AC4>\", 'output': '{\"component_types\": [\"fact\", \"fact\", \"policy\", \"policy\"]}'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    \n",
    "    print(data_file_train[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d724e7b-c002-45f3-ad2c-0341069d91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test = []\n",
    "\n",
    "for sample in cdcp_dataset[\"test\"]:\n",
    "\n",
    "    sample_text = sample[\"text\"]\n",
    "    start_l = sample[\"propositions\"][\"start\"]\n",
    "    end_l = sample[\"propositions\"][\"end\"]\n",
    "    raw_labels = sample[\"propositions\"][\"label\"]\n",
    "\n",
    "    instruction = write_instruction(len(raw_labels))\n",
    "    question = insert_tags(sample_text, start_l, end_l)\n",
    "    answer = get_ac_types(raw_labels)\n",
    "    \n",
    "    data_file_test.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef8d353-526e-48e4-89c4-d7e05082fd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1edc9c98-3134-4515-a301-28ef58864f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 3, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n', 'input': \"### Here is the text: <AC1>Recently, courts have held that debt collectors can escape 1692i's venue provisions entirely by pursuing debt collection through arbitration instead.</AC1><AC2> As the NAF studies reflect, arbitration has not proven a satisfactory alternative.</AC2><AC3> I urge the CFPB to include in a rule language interpreting 1692i as requiring debt collectors to proceed in court, not through largely-unregulated arbitral forums.</AC3>\", 'output': '{\"component_types\": [\"fact\", \"value\", \"policy\"]}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 5, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n', 'input': '### Here is the text: <AC1>When alleged debtors are served with state court summonses, they are not always comprehensible to laypersons.</AC1><AC2> Any requirements to file papers to avoid default judgment</AC2><AC3> The date of any scheduled hearing and procedures for changing the date</AC3><AC4> Local and online sources of information for pro se defendants, and possibly local non-profit advice organizations.</AC4><AC5> That the debtor may wish to consider bankruptcy if they cannot pay their debts.</AC5>', 'output': '{\"component_types\": [\"value\", \"policy\", \"policy\", \"policy\", \"policy\"]}'}\n",
      "\n",
      "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 2, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n', 'input': '### Here is the text: <AC1>To avoid consumers getting sued repeatedly on the same debt, the CFPB should require or encourage states to adopt rules requiring that judgments be preclusive of future consumer-collector litigation on the same debt;</AC1><AC2> instead, if there is a dispute between assignees as to who has title to the debt, they should work it out between themselves instead of risking subjecting the consumer to multiple liability.</AC2>', 'output': '{\"component_types\": [\"policy\", \"policy\"]}'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    \n",
    "    print(data_file_test[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8dad5-0a92-4460-a027-64e9d6ffba6a",
   "metadata": {},
   "source": [
    "## Save `jsonl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828863ac-a9f2-497a-8a1f-92b7685d1a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"../datasets/CDCP_acc_train.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0ed1c8-af63-42e5-831b-7a4b501241f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"../datasets/CDCP_acc_test.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test, file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6da58108-5314-4861-9e1e-58da1517f5b2",
   "metadata": {},
   "source": [
    "### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument components in the text as either \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 3, in following JSON format: {\"component_types\": [component_type (str), component_type (str), ..., component_type (str)]}\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
