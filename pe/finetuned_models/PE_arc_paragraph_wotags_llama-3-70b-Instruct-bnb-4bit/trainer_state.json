{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 1.9231230020523071,
      "learning_rate": 5.357142857142857e-06,
      "loss": 0.921,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.007701491937041283,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.0314,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.5309213995933533,
      "learning_rate": 2.3214285714285715e-05,
      "loss": 0.0256,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.0018969717202708125,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 0.0165,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.29260286688804626,
      "learning_rate": 4.107142857142857e-05,
      "loss": 0.0127,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.09419332444667816,
      "learning_rate": 5e-05,
      "loss": 0.0097,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.016985226422548294,
      "learning_rate": 4.99514478951133e-05,
      "loss": 0.0063,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.03125473111867905,
      "learning_rate": 4.9805980165004304e-05,
      "loss": 0.0043,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.022481320425868034,
      "learning_rate": 4.956416183083221e-05,
      "loss": 0.013,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.3682689070701599,
      "learning_rate": 4.922693215572695e-05,
      "loss": 0.011,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.3565104901790619,
      "learning_rate": 4.879560099653307e-05,
      "loss": 0.0041,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.05487730726599693,
      "learning_rate": 4.8328323420226664e-05,
      "loss": 0.0026,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.01422636117786169,
      "learning_rate": 4.778764630779183e-05,
      "loss": 0.0072,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.34495654702186584,
      "learning_rate": 4.7102884837615244e-05,
      "loss": 0.0127,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 19.331663131713867,
      "learning_rate": 4.6332272040803895e-05,
      "loss": 0.0091,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 3.873284339904785,
      "learning_rate": 4.5567784804325835e-05,
      "loss": 0.006,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.0496351458132267,
      "learning_rate": 4.464256698209684e-05,
      "loss": 0.0093,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.5880617499351501,
      "learning_rate": 4.364105412207914e-05,
      "loss": 0.0169,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.05429556220769882,
      "learning_rate": 4.256713626886673e-05,
      "loss": 0.0097,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.5605186223983765,
      "learning_rate": 4.1424984700239515e-05,
      "loss": 0.0101,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.8088809251785278,
      "learning_rate": 4.021903572521802e-05,
      "loss": 0.0115,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.24376225471496582,
      "learning_rate": 3.89539734526921e-05,
      "loss": 0.003,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.012787627056241035,
      "learning_rate": 3.7634711597553275e-05,
      "loss": 0.0028,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.5420718789100647,
      "learning_rate": 3.6266374394998634e-05,
      "loss": 0.0004,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.3912840485572815,
      "learning_rate": 3.485427669713849e-05,
      "loss": 0.0048,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.04680059850215912,
      "learning_rate": 3.3403903329215776e-05,
      "loss": 0.0004,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 8.979464530944824,
      "learning_rate": 3.1920887785621235e-05,
      "loss": 0.0048,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": Infinity,
      "learning_rate": 3.116893494225734e-05,
      "loss": 0.4978,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.19701257348060608,
      "learning_rate": 2.9647790179072872e-05,
      "loss": 0.2259,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 2.453397512435913,
      "learning_rate": 2.8108592616187133e-05,
      "loss": 0.0011,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 1.0041265487670898,
      "learning_rate": 2.6557320756121306e-05,
      "loss": 0.0076,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.08893851190805435,
      "learning_rate": 2.5e-05,
      "loss": 0.0019,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.005710610654205084,
      "learning_rate": 2.34426792438787e-05,
      "loss": 0.0047,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.21941843628883362,
      "learning_rate": 2.189140738381288e-05,
      "loss": 0.0027,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 1.1341499090194702,
      "learning_rate": 2.0352209820927137e-05,
      "loss": 0.0027,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.025614982470870018,
      "learning_rate": 1.8831065057742657e-05,
      "loss": 0.0015,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 4.3485331535339355,
      "learning_rate": 1.7333881476666647e-05,
      "loss": 0.0022,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.09947080165147781,
      "learning_rate": 1.5866474390840125e-05,
      "loss": 0.0006,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.0065065897069871426,
      "learning_rate": 1.443454345648252e-05,
      "loss": 0.0006,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 4.563254356384277,
      "learning_rate": 1.3043650534467053e-05,
      "loss": 0.0072,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.10974650084972382,
      "learning_rate": 1.1699198087116589e-05,
      "loss": 0.0004,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.03220290690660477,
      "learning_rate": 1.0406408194130259e-05,
      "loss": 0.0019,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.04091044142842293,
      "learning_rate": 9.170302269146508e-06,
      "loss": 0.0018,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.0022633997723460197,
      "learning_rate": 7.99568155572701e-06,
      "loss": 0.0005,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.0005925259320065379,
      "learning_rate": 6.8871084785181836e-06,
      "loss": 0.001,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.003324054880067706,
      "learning_rate": 5.848888922025553e-06,
      "loss": 0.001,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.0010282400762662292,
      "learning_rate": 4.885055505833291e-06,
      "loss": 0.0004,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.0026362815406173468,
      "learning_rate": 3.9993519212307154e-06,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.0027398355305194855,
      "learning_rate": 3.195218390084867e-06,
      "loss": 0.0022,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.021445143967866898,
      "learning_rate": 2.475778302439524e-06,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.046552665531635284,
      "learning_rate": 1.843826084742284e-06,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.002241564681753516,
      "learning_rate": 1.3018163458217076e-06,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.014437342062592506,
      "learning_rate": 8.51854342773295e-07,
      "loss": 0.0002,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.0007327406201511621,
      "learning_rate": 4.956878037864043e-07,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.0005516955861821771,
      "learning_rate": 2.3470013967367977e-07,
      "loss": 0.0002,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.0002772172156255692,
      "learning_rate": 6.990507047049676e-08,
      "loss": 0.0008,
      "step": 560
    },
    {
      "epoch": 4.988864142538976,
      "step": 560,
      "total_flos": 1.2130054771478364e+18,
      "train_loss": 0.03453790421855436,
      "train_runtime": 14449.5711,
      "train_samples_per_second": 0.621,
      "train_steps_per_second": 0.039
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2130054771478364e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
