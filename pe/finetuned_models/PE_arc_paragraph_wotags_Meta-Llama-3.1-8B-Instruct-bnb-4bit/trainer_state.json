{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 1120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 0.473291277885437,
      "learning_rate": 4.017857142857143e-06,
      "loss": 0.6164,
      "step": 10
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 2.0778098106384277,
      "learning_rate": 8.482142857142858e-06,
      "loss": 0.0376,
      "step": 20
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 0.32631999254226685,
      "learning_rate": 1.2946428571428574e-05,
      "loss": 0.0212,
      "step": 30
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.17261213064193726,
      "learning_rate": 1.7410714285714287e-05,
      "loss": 0.0303,
      "step": 40
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 0.5885224342346191,
      "learning_rate": 2.1875e-05,
      "loss": 0.0387,
      "step": 50
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.03130917623639107,
      "learning_rate": 2.6339285714285716e-05,
      "loss": 0.0118,
      "step": 60
    },
    {
      "epoch": 0.311804008908686,
      "grad_norm": 0.052296631038188934,
      "learning_rate": 3.080357142857143e-05,
      "loss": 0.0293,
      "step": 70
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.14175832271575928,
      "learning_rate": 3.5267857142857145e-05,
      "loss": 0.0178,
      "step": 80
    },
    {
      "epoch": 0.40089086859688194,
      "grad_norm": 1.0370352268218994,
      "learning_rate": 3.9732142857142855e-05,
      "loss": 0.0159,
      "step": 90
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.745529055595398,
      "learning_rate": 4.419642857142857e-05,
      "loss": 0.0449,
      "step": 100
    },
    {
      "epoch": 0.48997772828507796,
      "grad_norm": 0.34582769870758057,
      "learning_rate": 4.866071428571429e-05,
      "loss": 0.0173,
      "step": 110
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.003862557001411915,
      "learning_rate": 4.999405067699773e-05,
      "loss": 0.0288,
      "step": 120
    },
    {
      "epoch": 0.579064587973274,
      "grad_norm": 0.018063055351376534,
      "learning_rate": 4.996491795204623e-05,
      "loss": 0.0207,
      "step": 130
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.0025725997984409332,
      "learning_rate": 4.991153735294049e-05,
      "loss": 0.0073,
      "step": 140
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 0.009644243866205215,
      "learning_rate": 4.9833960727078975e-05,
      "loss": 0.0047,
      "step": 150
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.5717115998268127,
      "learning_rate": 4.9732263422927315e-05,
      "loss": 0.0207,
      "step": 160
    },
    {
      "epoch": 0.7572383073496659,
      "grad_norm": 0.34204795956611633,
      "learning_rate": 4.960654421683386e-05,
      "loss": 0.0218,
      "step": 170
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.0013682739809155464,
      "learning_rate": 4.94569252170905e-05,
      "loss": 0.0134,
      "step": 180
    },
    {
      "epoch": 0.8463251670378619,
      "grad_norm": 0.020105035975575447,
      "learning_rate": 4.9283551745331534e-05,
      "loss": 0.0169,
      "step": 190
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.26814791560173035,
      "learning_rate": 4.9086592195385974e-05,
      "loss": 0.0256,
      "step": 200
    },
    {
      "epoch": 0.9354120267260579,
      "grad_norm": 1.3642507791519165,
      "learning_rate": 4.886623786972033e-05,
      "loss": 0.0237,
      "step": 210
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.08434546738862991,
      "learning_rate": 4.8622702793630756e-05,
      "loss": 0.0049,
      "step": 220
    },
    {
      "epoch": 1.024498886414254,
      "grad_norm": 0.0007801834144629538,
      "learning_rate": 4.8356223507364996e-05,
      "loss": 0.0024,
      "step": 230
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.008375334553420544,
      "learning_rate": 4.8067058836376044e-05,
      "loss": 0.0005,
      "step": 240
    },
    {
      "epoch": 1.1135857461024499,
      "grad_norm": 0.00018837650713976473,
      "learning_rate": 4.775548963993072e-05,
      "loss": 0.0074,
      "step": 250
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.0037855065893381834,
      "learning_rate": 4.742181853831721e-05,
      "loss": 0.0132,
      "step": 260
    },
    {
      "epoch": 1.2026726057906458,
      "grad_norm": 0.020740646868944168,
      "learning_rate": 4.706636961891673e-05,
      "loss": 0.0092,
      "step": 270
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.07357207685709,
      "learning_rate": 4.668948812142453e-05,
      "loss": 0.012,
      "step": 280
    },
    {
      "epoch": 1.2917594654788418,
      "grad_norm": 0.0015931226080283523,
      "learning_rate": 4.6291540102526235e-05,
      "loss": 0.0081,
      "step": 290
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.9433924555778503,
      "learning_rate": 4.587291208035503e-05,
      "loss": 0.0106,
      "step": 300
    },
    {
      "epoch": 1.3808463251670378,
      "grad_norm": 0.0004752320237457752,
      "learning_rate": 4.543401065907516e-05,
      "loss": 0.0058,
      "step": 310
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 1.5965700149536133,
      "learning_rate": 4.497526213395623e-05,
      "loss": 0.0203,
      "step": 320
    },
    {
      "epoch": 1.469933184855234,
      "grad_norm": 0.8694811463356018,
      "learning_rate": 4.4497112077322044e-05,
      "loss": 0.0164,
      "step": 330
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.38016223907470703,
      "learning_rate": 4.400002490577604e-05,
      "loss": 0.0146,
      "step": 340
    },
    {
      "epoch": 1.5590200445434297,
      "grad_norm": 0.607772946357727,
      "learning_rate": 4.3484483429123656e-05,
      "loss": 0.0239,
      "step": 350
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.005420972127467394,
      "learning_rate": 4.295098838142985e-05,
      "loss": 0.0121,
      "step": 360
    },
    {
      "epoch": 1.6481069042316259,
      "grad_norm": 0.015320650301873684,
      "learning_rate": 4.240005793466709e-05,
      "loss": 0.0177,
      "step": 370
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.7344120740890503,
      "learning_rate": 4.183222719542643e-05,
      "loss": 0.0112,
      "step": 380
    },
    {
      "epoch": 1.7371937639198218,
      "grad_norm": 0.00020383951778057963,
      "learning_rate": 4.1248047685180215e-05,
      "loss": 0.0071,
      "step": 390
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.5946328043937683,
      "learning_rate": 4.064808680460148e-05,
      "loss": 0.0072,
      "step": 400
    },
    {
      "epoch": 1.8262806236080178,
      "grad_norm": 0.00014596484834328294,
      "learning_rate": 4.0032927282460146e-05,
      "loss": 0.0027,
      "step": 410
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.18262438476085663,
      "learning_rate": 3.940316660963147e-05,
      "loss": 0.0155,
      "step": 420
    },
    {
      "epoch": 1.9153674832962138,
      "grad_norm": 0.0007953480235300958,
      "learning_rate": 3.875941645876631e-05,
      "loss": 0.0064,
      "step": 430
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.16864195466041565,
      "learning_rate": 3.810230209018694e-05,
      "loss": 0.0052,
      "step": 440
    },
    {
      "epoch": 2.0044543429844097,
      "grad_norm": 0.7897658944129944,
      "learning_rate": 3.74324617445856e-05,
      "loss": 0.0054,
      "step": 450
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.0006361788837239146,
      "learning_rate": 3.6750546023115216e-05,
      "loss": 0.0006,
      "step": 460
    },
    {
      "epoch": 2.093541202672606,
      "grad_norm": 0.033065661787986755,
      "learning_rate": 3.6057217255475034e-05,
      "loss": 0.0039,
      "step": 470
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 1.011567234992981,
      "learning_rate": 3.535314885660426e-05,
      "loss": 0.0042,
      "step": 480
    },
    {
      "epoch": 2.1826280623608016,
      "grad_norm": 0.0019682557322084904,
      "learning_rate": 3.463902467260905e-05,
      "loss": 0.0119,
      "step": 490
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.03807681426405907,
      "learning_rate": 3.391553831655782e-05,
      "loss": 0.005,
      "step": 500
    },
    {
      "epoch": 2.271714922048998,
      "grad_norm": 0.0016689442563802004,
      "learning_rate": 3.318339249479026e-05,
      "loss": 0.0116,
      "step": 510
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.13242146372795105,
      "learning_rate": 3.244329832439404e-05,
      "loss": 0.0017,
      "step": 520
    },
    {
      "epoch": 2.3608017817371936,
      "grad_norm": 0.6087898015975952,
      "learning_rate": 3.1695974642512585e-05,
      "loss": 0.0162,
      "step": 530
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.13972410559654236,
      "learning_rate": 3.094214730815433e-05,
      "loss": 0.0083,
      "step": 540
    },
    {
      "epoch": 2.4498886414253898,
      "grad_norm": 0.06751757115125656,
      "learning_rate": 3.0182548497181946e-05,
      "loss": 0.0016,
      "step": 550
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 0.0005305816885083914,
      "learning_rate": 2.9417915991166008e-05,
      "loss": 0.011,
      "step": 560
    },
    {
      "epoch": 2.538975501113586,
      "grad_norm": 0.0033354253973811865,
      "learning_rate": 2.8648992460794056e-05,
      "loss": 0.0046,
      "step": 570
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.021921344101428986,
      "learning_rate": 2.787652474453097e-05,
      "loss": 0.0214,
      "step": 580
    },
    {
      "epoch": 2.6280623608017817,
      "grad_norm": 0.026410115882754326,
      "learning_rate": 2.710126312323119e-05,
      "loss": 0.0042,
      "step": 590
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.0017968789907172322,
      "learning_rate": 2.632396059140749e-05,
      "loss": 0.003,
      "step": 600
    },
    {
      "epoch": 2.717149220489978,
      "grad_norm": 0.34287774562835693,
      "learning_rate": 2.5545372125864032e-05,
      "loss": 0.0049,
      "step": 610
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 0.45874547958374023,
      "learning_rate": 2.4766253952404024e-05,
      "loss": 0.0021,
      "step": 620
    },
    {
      "epoch": 2.8062360801781736,
      "grad_norm": 0.042565230280160904,
      "learning_rate": 2.3987362811324298e-05,
      "loss": 0.0026,
      "step": 630
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.0004628792521543801,
      "learning_rate": 2.3209455222410122e-05,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 2.89532293986637,
      "grad_norm": 0.0004764603800140321,
      "learning_rate": 2.2433286750144293e-05,
      "loss": 0.0004,
      "step": 650
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.00034928935929201543,
      "learning_rate": 2.1659611269843906e-05,
      "loss": 0.0123,
      "step": 660
    },
    {
      "epoch": 2.984409799554566,
      "grad_norm": 0.0005704094073735178,
      "learning_rate": 2.0889180235437976e-05,
      "loss": 0.0084,
      "step": 670
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.3494856059551239,
      "learning_rate": 2.0122741949596797e-05,
      "loss": 0.0019,
      "step": 680
    },
    {
      "epoch": 3.0734966592427617,
      "grad_norm": 0.0013566470006480813,
      "learning_rate": 1.936104083692202e-05,
      "loss": 0.0012,
      "step": 690
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.02058357745409012,
      "learning_rate": 1.86048167209035e-05,
      "loss": 0.0006,
      "step": 700
    },
    {
      "epoch": 3.1625835189309575,
      "grad_norm": 0.3077711760997772,
      "learning_rate": 1.7854804105345062e-05,
      "loss": 0.0011,
      "step": 710
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.0004297242849133909,
      "learning_rate": 1.711173146095712e-05,
      "loss": 0.0011,
      "step": 720
    },
    {
      "epoch": 3.2516703786191536,
      "grad_norm": 0.5311760306358337,
      "learning_rate": 1.637632051780917e-05,
      "loss": 0.0021,
      "step": 730
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.0011153609957545996,
      "learning_rate": 1.5649285564329296e-05,
      "loss": 0.0003,
      "step": 740
    },
    {
      "epoch": 3.34075723830735,
      "grad_norm": 0.09804905205965042,
      "learning_rate": 1.4931332753531574e-05,
      "loss": 0.0004,
      "step": 750
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.00014541533892042935,
      "learning_rate": 1.4223159417145179e-05,
      "loss": 0.0002,
      "step": 760
    },
    {
      "epoch": 3.4298440979955456,
      "grad_norm": 0.029494604095816612,
      "learning_rate": 1.3525453388311554e-05,
      "loss": 0.0002,
      "step": 770
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.0001513312163297087,
      "learning_rate": 1.2838892333507154e-05,
      "loss": 0.0006,
      "step": 780
    },
    {
      "epoch": 3.5189309576837418,
      "grad_norm": 0.0004744244506582618,
      "learning_rate": 1.2164143094340993e-05,
      "loss": 0.0002,
      "step": 790
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 1.799553632736206,
      "learning_rate": 1.1501861039866094e-05,
      "loss": 0.0129,
      "step": 800
    },
    {
      "epoch": 3.6080178173719375,
      "grad_norm": 0.0012443786254152656,
      "learning_rate": 1.0852689430033972e-05,
      "loss": 0.0001,
      "step": 810
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.007930310443043709,
      "learning_rate": 1.0217258790910448e-05,
      "loss": 0.0001,
      "step": 820
    },
    {
      "epoch": 3.6971046770601337,
      "grad_norm": 0.001372919767163694,
      "learning_rate": 9.596186302259563e-06,
      "loss": 0.002,
      "step": 830
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.017573095858097076,
      "learning_rate": 8.99007519809053e-06,
      "loss": 0.0057,
      "step": 840
    },
    {
      "epoch": 3.78619153674833,
      "grad_norm": 0.07833671569824219,
      "learning_rate": 8.399514180749795e-06,
      "loss": 0.0031,
      "step": 850
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.001365303061902523,
      "learning_rate": 7.825076849127458e-06,
      "loss": 0.0029,
      "step": 860
    },
    {
      "epoch": 3.8752783964365256,
      "grad_norm": 0.002058675978332758,
      "learning_rate": 7.26732114153334e-06,
      "loss": 0.0008,
      "step": 870
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.0011658569565042853,
      "learning_rate": 6.72678879378377e-06,
      "loss": 0.0004,
      "step": 880
    },
    {
      "epoch": 3.9643652561247213,
      "grad_norm": 0.004222737159579992,
      "learning_rate": 6.204004813025568e-06,
      "loss": 0.0005,
      "step": 890
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.002287105889990926,
      "learning_rate": 5.699476967808168e-06,
      "loss": 0.0005,
      "step": 900
    },
    {
      "epoch": 4.0534521158129175,
      "grad_norm": 0.001185538014397025,
      "learning_rate": 5.2136952948992346e-06,
      "loss": 0.0003,
      "step": 910
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.008086202666163445,
      "learning_rate": 4.747131623322737e-06,
      "loss": 0.0003,
      "step": 920
    },
    {
      "epoch": 4.142538975501114,
      "grad_norm": 0.008663316257297993,
      "learning_rate": 4.3002391160818775e-06,
      "loss": 0.0002,
      "step": 930
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.0014694544952362776,
      "learning_rate": 3.873451830011795e-06,
      "loss": 0.0003,
      "step": 940
    },
    {
      "epoch": 4.23162583518931,
      "grad_norm": 0.000388723099604249,
      "learning_rate": 3.4671842941897765e-06,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.013906250707805157,
      "learning_rate": 3.081831107312308e-06,
      "loss": 0.0002,
      "step": 960
    },
    {
      "epoch": 4.320712694877505,
      "grad_norm": 0.0020043489057570696,
      "learning_rate": 2.717766554430043e-06,
      "loss": 0.0003,
      "step": 970
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.0033838350791484118,
      "learning_rate": 2.3753442434129997e-06,
      "loss": 0.0011,
      "step": 980
    },
    {
      "epoch": 4.409799554565701,
      "grad_norm": 0.04073227196931839,
      "learning_rate": 2.0548967614990507e-06,
      "loss": 0.0002,
      "step": 990
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.004555109888315201,
      "learning_rate": 1.7567353522592477e-06,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 4.498886414253898,
      "grad_norm": 0.0038671933580189943,
      "learning_rate": 1.4811496132938196e-06,
      "loss": 0.0002,
      "step": 1010
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.004683484323322773,
      "learning_rate": 1.2284072149524094e-06,
      "loss": 0.0002,
      "step": 1020
    },
    {
      "epoch": 4.587973273942094,
      "grad_norm": 0.0012249151477590203,
      "learning_rate": 9.98753640351785e-07,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.0002677948505152017,
      "learning_rate": 7.924119469434665e-07,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 4.67706013363029,
      "grad_norm": 0.0005903882556594908,
      "learning_rate": 6.095825498629692e-07,
      "loss": 0.0002,
      "step": 1050
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.01693868450820446,
      "learning_rate": 4.5044302727100806e-07,
      "loss": 0.0002,
      "step": 1060
    },
    {
      "epoch": 4.766146993318485,
      "grad_norm": 0.0033473726361989975,
      "learning_rate": 3.1514794787571854e-07,
      "loss": 0.0001,
      "step": 1070
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.0007440614863298833,
      "learning_rate": 2.0382872080351166e-07,
      "loss": 0.0034,
      "step": 1080
    },
    {
      "epoch": 4.855233853006681,
      "grad_norm": 0.000627277244348079,
      "learning_rate": 1.1659346796426551e-07,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.0033653522841632366,
      "learning_rate": 5.352691903491303e-08,
      "loss": 0.0002,
      "step": 1100
    },
    {
      "epoch": 4.944320712694878,
      "grad_norm": 0.02298646979033947,
      "learning_rate": 1.4690329163363769e-08,
      "loss": 0.0002,
      "step": 1110
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.004493203014135361,
      "learning_rate": 1.214194727400253e-10,
      "loss": 0.0001,
      "step": 1120
    },
    {
      "epoch": 4.988864142538976,
      "step": 1120,
      "total_flos": 1.3115072237233766e+17,
      "train_loss": 0.013322809946319986,
      "train_runtime": 4386.7261,
      "train_samples_per_second": 2.047,
      "train_steps_per_second": 0.255
    }
  ],
  "logging_steps": 10,
  "max_steps": 1120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3115072237233766e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
