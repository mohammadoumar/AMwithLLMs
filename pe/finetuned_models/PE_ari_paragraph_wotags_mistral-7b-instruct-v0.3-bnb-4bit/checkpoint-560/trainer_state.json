{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 2.8031790256500244,
      "learning_rate": 7.142857142857143e-06,
      "loss": 1.2545,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.7650275230407715,
      "learning_rate": 1.6071428571428572e-05,
      "loss": 0.0746,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 1.0152308940887451,
      "learning_rate": 2.5e-05,
      "loss": 0.0433,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.4225464463233948,
      "learning_rate": 3.392857142857143e-05,
      "loss": 0.0387,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 1.2026493549346924,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.0394,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 1.3461878299713135,
      "learning_rate": 4.9998057312024373e-05,
      "loss": 0.0532,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.18083196878433228,
      "learning_rate": 4.9930094929529506e-05,
      "loss": 0.0426,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 1.664078950881958,
      "learning_rate": 4.976529986032632e-05,
      "loss": 0.0467,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 1.4183186292648315,
      "learning_rate": 4.9504312196213596e-05,
      "loss": 0.0475,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.9240179061889648,
      "learning_rate": 4.914814565722671e-05,
      "loss": 0.0344,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.9006959795951843,
      "learning_rate": 4.86981836541783e-05,
      "loss": 0.0299,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.37000444531440735,
      "learning_rate": 4.815617391525772e-05,
      "loss": 0.0284,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 1.0322539806365967,
      "learning_rate": 4.752422169756048e-05,
      "loss": 0.0367,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.36201682686805725,
      "learning_rate": 4.680478160991514e-05,
      "loss": 0.0314,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.3971721827983856,
      "learning_rate": 4.600064807876929e-05,
      "loss": 0.0228,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": NaN,
      "learning_rate": 4.54788011072248e-05,
      "loss": 0.7025,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.46567821502685547,
      "learning_rate": 4.4738583707505885e-05,
      "loss": 1.3826,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.5151456594467163,
      "learning_rate": 4.374453007419336e-05,
      "loss": 0.0341,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.17462852597236633,
      "learning_rate": 4.267766952966369e-05,
      "loss": 0.0231,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.3533688485622406,
      "learning_rate": 4.154214593992149e-05,
      "loss": 0.0234,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.1593083143234253,
      "learning_rate": 4.034236986980119e-05,
      "loss": 0.0176,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.572575032711029,
      "learning_rate": 3.908300145159055e-05,
      "loss": 0.0244,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.25954923033714294,
      "learning_rate": 3.7768932284292146e-05,
      "loss": 0.0211,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.32073909044265747,
      "learning_rate": 3.6405266433829075e-05,
      "loss": 0.0125,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.08602435886859894,
      "learning_rate": 3.499730060799352e-05,
      "loss": 0.0128,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.5796425938606262,
      "learning_rate": 3.355050358314172e-05,
      "loss": 0.0192,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.5882841944694519,
      "learning_rate": 3.207049496254569e-05,
      "loss": 0.0144,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 2.160785436630249,
      "learning_rate": 3.056302334890786e-05,
      "loss": 0.0216,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.2509059011936188,
      "learning_rate": 2.903394401582017e-05,
      "loss": 0.0185,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.7488900423049927,
      "learning_rate": 2.748919616489542e-05,
      "loss": 0.0254,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 1.875314474105835,
      "learning_rate": 2.593477985690815e-05,
      "loss": 0.0255,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.362628310918808,
      "learning_rate": 2.4376732706548183e-05,
      "loss": 0.0205,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.30716896057128906,
      "learning_rate": 2.2821106431308544e-05,
      "loss": 0.0194,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.31792962551116943,
      "learning_rate": 2.1273943345595637e-05,
      "loss": 0.0153,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.5399330854415894,
      "learning_rate": 1.9741252891362612e-05,
      "loss": 0.0072,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.371724933385849,
      "learning_rate": 1.8228988296424877e-05,
      "loss": 0.0087,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.28601232171058655,
      "learning_rate": 1.6743023451120832e-05,
      "loss": 0.0118,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.19144882261753082,
      "learning_rate": 1.5289130093132632e-05,
      "loss": 0.0124,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.05891769006848335,
      "learning_rate": 1.387295538908519e-05,
      "loss": 0.0086,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 0.4835277795791626,
      "learning_rate": 1.2500000000000006e-05,
      "loss": 0.005,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.30748653411865234,
      "learning_rate": 1.1175596715801515e-05,
      "loss": 0.0105,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.23658782243728638,
      "learning_rate": 9.90488974186306e-06,
      "loss": 0.0086,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.34814566373825073,
      "learning_rate": 8.69281471804698e-06,
      "loss": 0.0126,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.1631934493780136,
      "learning_rate": 7.5440795478481815e-06,
      "loss": 0.0066,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.16105656325817108,
      "learning_rate": 6.463146112104332e-06,
      "loss": 0.0092,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.07229761779308319,
      "learning_rate": 5.454212938299255e-06,
      "loss": 0.003,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.24294383823871613,
      "learning_rate": 4.521198892775203e-06,
      "loss": 0.0026,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.0797390341758728,
      "learning_rate": 3.66772795919611e-06,
      "loss": 0.0013,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.17158247530460358,
      "learning_rate": 2.8971151623847587e-06,
      "loss": 0.0022,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.060585323721170425,
      "learning_rate": 2.212353692208172e-06,
      "loss": 0.0024,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.1759035736322403,
      "learning_rate": 1.6161032775241503e-06,
      "loss": 0.0024,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.13167840242385864,
      "learning_rate": 1.1106798553464804e-06,
      "loss": 0.0027,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.3290773630142212,
      "learning_rate": 6.980465753556376e-07,
      "loss": 0.0027,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.0357448048889637,
      "learning_rate": 3.7980617469479953e-07,
      "loss": 0.0025,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.07463105022907257,
      "learning_rate": 1.571947526689349e-07,
      "loss": 0.0041,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.2814902365207672,
      "learning_rate": 3.107696952694139e-08,
      "loss": 0.0022,
      "step": 560
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.089127757822034e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
