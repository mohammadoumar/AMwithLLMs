{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 3.2558906078338623,
      "learning_rate": 7.142857142857143e-06,
      "loss": 1.4154,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.49832794070243835,
      "learning_rate": 1.6071428571428572e-05,
      "loss": 0.0274,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.16260485351085663,
      "learning_rate": 2.5e-05,
      "loss": 0.027,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.013025129213929176,
      "learning_rate": 3.392857142857143e-05,
      "loss": 0.0134,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.3853136897087097,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.0123,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.06769206374883652,
      "learning_rate": 4.9998057312024373e-05,
      "loss": 0.0139,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.4039020240306854,
      "learning_rate": 4.9930094929529506e-05,
      "loss": 0.0088,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.11887727677822113,
      "learning_rate": 4.976529986032632e-05,
      "loss": 0.0135,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.0015477064298465848,
      "learning_rate": 4.9504312196213596e-05,
      "loss": 0.0113,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.16537344455718994,
      "learning_rate": 4.914814565722671e-05,
      "loss": 0.0199,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.17692868411540985,
      "learning_rate": 4.86981836541783e-05,
      "loss": 0.0203,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.005402024369686842,
      "learning_rate": 4.815617391525772e-05,
      "loss": 0.0051,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.002375662326812744,
      "learning_rate": 4.752422169756048e-05,
      "loss": 0.0065,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.16000519692897797,
      "learning_rate": 4.680478160991514e-05,
      "loss": 0.0098,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.2523249089717865,
      "learning_rate": 4.600064807876929e-05,
      "loss": 0.0082,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 1.1994837522506714,
      "learning_rate": 4.511494449416671e-05,
      "loss": 0.0104,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.30751779675483704,
      "learning_rate": 4.415111107797445e-05,
      "loss": 0.0056,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.027589591220021248,
      "learning_rate": 4.311289152148182e-05,
      "loss": 0.0028,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.08716776221990585,
      "learning_rate": 4.2004318444272985e-05,
      "loss": 0.0128,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.32431700825691223,
      "learning_rate": 4.08296977308535e-05,
      "loss": 0.0102,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.0018484854372218251,
      "learning_rate": 3.959359180586975e-05,
      "loss": 0.0045,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.2656945586204529,
      "learning_rate": 3.830080191288342e-05,
      "loss": 0.0067,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.031626418232917786,
      "learning_rate": 3.695634946553296e-05,
      "loss": 0.0035,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.01380610466003418,
      "learning_rate": 3.556545654351749e-05,
      "loss": 0.0015,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.00026414982858113945,
      "learning_rate": 3.413352560915988e-05,
      "loss": 0.0008,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.03655609115958214,
      "learning_rate": 3.266611852333336e-05,
      "loss": 0.0001,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.13146370649337769,
      "learning_rate": 3.116893494225734e-05,
      "loss": 0.0074,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 0.09625113755464554,
      "learning_rate": 2.9647790179072872e-05,
      "loss": 0.0091,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.02177896909415722,
      "learning_rate": 2.8108592616187133e-05,
      "loss": 0.0038,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.00876531284302473,
      "learning_rate": 2.6557320756121306e-05,
      "loss": 0.0032,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 0.0031667929142713547,
      "learning_rate": 2.5e-05,
      "loss": 0.002,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.0005714228609576821,
      "learning_rate": 2.34426792438787e-05,
      "loss": 0.0007,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.0006044367328286171,
      "learning_rate": 2.189140738381288e-05,
      "loss": 0.0001,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.10667162388563156,
      "learning_rate": 2.0352209820927137e-05,
      "loss": 0.0059,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.564681351184845,
      "learning_rate": 1.8831065057742657e-05,
      "loss": 0.0011,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.0024435261730104685,
      "learning_rate": 1.7333881476666647e-05,
      "loss": 0.001,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.0035719412844628096,
      "learning_rate": 1.5866474390840125e-05,
      "loss": 0.0051,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.0060478635132312775,
      "learning_rate": 1.443454345648252e-05,
      "loss": 0.0004,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.005803260020911694,
      "learning_rate": 1.3043650534467053e-05,
      "loss": 0.0004,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 0.07815530896186829,
      "learning_rate": 1.1699198087116589e-05,
      "loss": 0.0004,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.004917448852211237,
      "learning_rate": 1.0406408194130259e-05,
      "loss": 0.0002,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.002969550434499979,
      "learning_rate": 9.170302269146508e-06,
      "loss": 0.001,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.0011725988006219268,
      "learning_rate": 7.99568155572701e-06,
      "loss": 0.001,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.0007029225816950202,
      "learning_rate": 6.8871084785181836e-06,
      "loss": 0.0001,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.0008003771072253585,
      "learning_rate": 5.848888922025553e-06,
      "loss": 0.002,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.0029026572592556477,
      "learning_rate": 4.885055505833291e-06,
      "loss": 0.0005,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.0017707631923258305,
      "learning_rate": 3.9993519212307154e-06,
      "loss": 0.0001,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.0057404362596571445,
      "learning_rate": 3.195218390084867e-06,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.00420872587710619,
      "learning_rate": 2.475778302439524e-06,
      "loss": 0.0002,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.0015246140537783504,
      "learning_rate": 1.843826084742284e-06,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.0032820056658238173,
      "learning_rate": 1.3018163458217076e-06,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.0023676035925745964,
      "learning_rate": 8.51854342773295e-07,
      "loss": 0.0002,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.003218592843040824,
      "learning_rate": 4.956878037864043e-07,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.00127700949087739,
      "learning_rate": 2.3470013967367977e-07,
      "loss": 0.0001,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.001349174533970654,
      "learning_rate": 6.990507047049676e-08,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.0020230060908943415,
      "learning_rate": 1.9426879756284656e-09,
      "loss": 0.0001,
      "step": 560
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4787095229261414e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
