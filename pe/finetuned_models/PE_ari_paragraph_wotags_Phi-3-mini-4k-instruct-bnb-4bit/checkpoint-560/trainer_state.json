{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 0.6839152574539185,
      "learning_rate": 8.92857142857143e-06,
      "loss": 0.4422,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.18913517892360687,
      "learning_rate": 1.785714285714286e-05,
      "loss": 0.1589,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.14958181977272034,
      "learning_rate": 2.6785714285714288e-05,
      "loss": 0.1033,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.15247192978858948,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.0544,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.1326676905155182,
      "learning_rate": 4.464285714285715e-05,
      "loss": 0.0514,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.10463966429233551,
      "learning_rate": 4.999222955002041e-05,
      "loss": 0.0429,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.054828934371471405,
      "learning_rate": 4.990486745229364e-05,
      "loss": 0.0333,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.20124883949756622,
      "learning_rate": 4.972077065562821e-05,
      "loss": 0.0356,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.11207520961761475,
      "learning_rate": 4.944065422298262e-05,
      "loss": 0.0423,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.08862899243831635,
      "learning_rate": 4.90656061737503e-05,
      "loss": 0.0276,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.13346396386623383,
      "learning_rate": 4.8597083257709194e-05,
      "loss": 0.0292,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.03018270991742611,
      "learning_rate": 4.803690529676019e-05,
      "loss": 0.0288,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.07968223094940186,
      "learning_rate": 4.738724811643252e-05,
      "loss": 0.0248,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.09959320724010468,
      "learning_rate": 4.665063509461097e-05,
      "loss": 0.0279,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.13927337527275085,
      "learning_rate": 4.582992736031123e-05,
      "loss": 0.017,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 0.11870365589857101,
      "learning_rate": 4.4928312680573064e-05,
      "loss": 0.023,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.1074996218085289,
      "learning_rate": 4.394929307863633e-05,
      "loss": 0.0299,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.11020588129758835,
      "learning_rate": 4.2896671231492966e-05,
      "loss": 0.0313,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.04553745314478874,
      "learning_rate": 4.1774535699649255e-05,
      "loss": 0.0207,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.14029604196548462,
      "learning_rate": 4.058724504646834e-05,
      "loss": 0.0249,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.057648468762636185,
      "learning_rate": 3.933941090877615e-05,
      "loss": 0.0192,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.06573843955993652,
      "learning_rate": 3.803588008448745e-05,
      "loss": 0.028,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.03443649411201477,
      "learning_rate": 3.668171570682655e-05,
      "loss": 0.0207,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.04791504144668579,
      "learning_rate": 3.5282177578265296e-05,
      "loss": 0.0142,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.11954360455274582,
      "learning_rate": 3.3842701740564534e-05,
      "loss": 0.0181,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.09685572236776352,
      "learning_rate": 3.2368879360272606e-05,
      "loss": 0.0143,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.08625216782093048,
      "learning_rate": 3.0866435011692885e-05,
      "loss": 0.0166,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 0.11760592460632324,
      "learning_rate": 2.9341204441673266e-05,
      "loss": 0.0144,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.04190998896956444,
      "learning_rate": 2.7799111902582696e-05,
      "loss": 0.0144,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.2115912139415741,
      "learning_rate": 2.624614714151743e-05,
      "loss": 0.0279,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 0.11895047873258591,
      "learning_rate": 2.4688342135114627e-05,
      "loss": 0.019,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.17647042870521545,
      "learning_rate": 2.3131747660339394e-05,
      "loss": 0.0168,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.112425297498703,
      "learning_rate": 2.158240979224817e-05,
      "loss": 0.0196,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.1875823736190796,
      "learning_rate": 2.0046346420015067e-05,
      "loss": 0.0153,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.049568600952625275,
      "learning_rate": 1.852952387243698e-05,
      "loss": 0.0086,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.06343720853328705,
      "learning_rate": 1.7037833743707892e-05,
      "loss": 0.0085,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.09536171704530716,
      "learning_rate": 1.557707000947487e-05,
      "loss": 0.0145,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.13362951576709747,
      "learning_rate": 1.4152906522061048e-05,
      "loss": 0.0142,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.06833169609308243,
      "learning_rate": 1.2770874972267777e-05,
      "loss": 0.0095,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 0.119293712079525,
      "learning_rate": 1.1436343403356017e-05,
      "loss": 0.0096,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.05687931925058365,
      "learning_rate": 1.0154495360662464e-05,
      "loss": 0.0094,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.08011309802532196,
      "learning_rate": 8.930309757836517e-06,
      "loss": 0.0099,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.10075126588344574,
      "learning_rate": 7.768541537901325e-06,
      "loss": 0.0129,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.054445065557956696,
      "learning_rate": 6.673703204254347e-06,
      "loss": 0.0071,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.07352384179830551,
      "learning_rate": 5.650047293344315e-06,
      "loss": 0.0108,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.020898282527923584,
      "learning_rate": 4.701549857103588e-06,
      "loss": 0.0069,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.1027662381529808,
      "learning_rate": 3.831895019292897e-06,
      "loss": 0.0063,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.15554817020893097,
      "learning_rate": 3.044460665744284e-06,
      "loss": 0.0043,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.08086241781711578,
      "learning_rate": 2.3423053240837515e-06,
      "loss": 0.0058,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.055140070617198944,
      "learning_rate": 1.7281562838948966e-06,
      "loss": 0.0058,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.10921057313680649,
      "learning_rate": 1.204399003466941e-06,
      "loss": 0.0055,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.05331860110163689,
      "learning_rate": 7.730678442730538e-07,
      "loss": 0.0046,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.08757826685905457,
      "learning_rate": 4.358381691677932e-07,
      "loss": 0.0099,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.02171916514635086,
      "learning_rate": 1.9401983499569842e-07,
      "loss": 0.0085,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.028366941958665848,
      "learning_rate": 4.855210488670381e-08,
      "loss": 0.0081,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.058583252131938934,
      "learning_rate": 0.0,
      "loss": 0.0061,
      "step": 560
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.859129524486144e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
