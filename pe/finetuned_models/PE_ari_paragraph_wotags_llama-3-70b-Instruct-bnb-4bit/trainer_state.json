{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.988864142538976,
  "eval_steps": 500,
  "global_step": 560,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 3.345754384994507,
      "learning_rate": 5.357142857142857e-06,
      "loss": 1.1643,
      "step": 10
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 0.39126503467559814,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.1763,
      "step": 20
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 0.33031389117240906,
      "learning_rate": 2.3214285714285715e-05,
      "loss": 0.0773,
      "step": 30
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 0.1045396625995636,
      "learning_rate": 3.2142857142857144e-05,
      "loss": 0.0367,
      "step": 40
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 0.2515368163585663,
      "learning_rate": 4.107142857142857e-05,
      "loss": 0.0406,
      "step": 50
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 0.2514028251171112,
      "learning_rate": 5e-05,
      "loss": 0.0353,
      "step": 60
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 0.052706554532051086,
      "learning_rate": 4.99514478951133e-05,
      "loss": 0.0295,
      "step": 70
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 0.28779807686805725,
      "learning_rate": 4.9805980165004304e-05,
      "loss": 0.0381,
      "step": 80
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 0.20667067170143127,
      "learning_rate": 4.956416183083221e-05,
      "loss": 0.0357,
      "step": 90
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 0.09289338439702988,
      "learning_rate": 4.922693215572695e-05,
      "loss": 0.0171,
      "step": 100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 0.07462538778781891,
      "learning_rate": 4.879560099653307e-05,
      "loss": 0.0308,
      "step": 110
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 0.026149770244956017,
      "learning_rate": 4.827184371610511e-05,
      "loss": 0.0205,
      "step": 120
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 0.09383102506399155,
      "learning_rate": 4.765769467591625e-05,
      "loss": 0.0152,
      "step": 130
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 0.06069489195942879,
      "learning_rate": 4.6955539334255716e-05,
      "loss": 0.0206,
      "step": 140
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 0.1226784810423851,
      "learning_rate": 4.6168104980707107e-05,
      "loss": 0.0139,
      "step": 150
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 0.09431321918964386,
      "learning_rate": 4.529845014289642e-05,
      "loss": 0.0184,
      "step": 160
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 0.12229236215353012,
      "learning_rate": 4.434995270665569e-05,
      "loss": 0.026,
      "step": 170
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 0.39625921845436096,
      "learning_rate": 4.332629679574566e-05,
      "loss": 0.0255,
      "step": 180
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 0.034269485622644424,
      "learning_rate": 4.223145846209868e-05,
      "loss": 0.0175,
      "step": 190
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 0.10821115970611572,
      "learning_rate": 4.1069690242163484e-05,
      "loss": 0.0223,
      "step": 200
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 0.04924061521887779,
      "learning_rate": 3.9845504639337535e-05,
      "loss": 0.0204,
      "step": 210
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 0.1409514993429184,
      "learning_rate": 3.856365659664399e-05,
      "loss": 0.0226,
      "step": 220
    },
    {
      "epoch": 2.048997772828508,
      "grad_norm": 0.03791544958949089,
      "learning_rate": 3.722912502773224e-05,
      "loss": 0.0138,
      "step": 230
    },
    {
      "epoch": 2.138084632516704,
      "grad_norm": 0.16873838007450104,
      "learning_rate": 3.5847093477938956e-05,
      "loss": 0.0096,
      "step": 240
    },
    {
      "epoch": 2.2271714922048997,
      "grad_norm": 0.01517882477492094,
      "learning_rate": 3.442292999052513e-05,
      "loss": 0.0164,
      "step": 250
    },
    {
      "epoch": 2.316258351893096,
      "grad_norm": 0.15348002314567566,
      "learning_rate": 3.2962166256292113e-05,
      "loss": 0.0151,
      "step": 260
    },
    {
      "epoch": 2.4053452115812917,
      "grad_norm": 0.12619931995868683,
      "learning_rate": 3.147047612756302e-05,
      "loss": 0.0113,
      "step": 270
    },
    {
      "epoch": 2.494432071269488,
      "grad_norm": 0.12905196845531464,
      "learning_rate": 2.9953653579984942e-05,
      "loss": 0.0131,
      "step": 280
    },
    {
      "epoch": 2.5835189309576836,
      "grad_norm": 0.020382001996040344,
      "learning_rate": 2.841759020775184e-05,
      "loss": 0.0116,
      "step": 290
    },
    {
      "epoch": 2.6726057906458798,
      "grad_norm": 0.17105938494205475,
      "learning_rate": 2.686825233966061e-05,
      "loss": 0.0216,
      "step": 300
    },
    {
      "epoch": 2.7616926503340755,
      "grad_norm": 0.07274827361106873,
      "learning_rate": 2.531165786488538e-05,
      "loss": 0.0148,
      "step": 310
    },
    {
      "epoch": 2.8507795100222717,
      "grad_norm": 0.11200828105211258,
      "learning_rate": 2.375385285848257e-05,
      "loss": 0.013,
      "step": 320
    },
    {
      "epoch": 2.939866369710468,
      "grad_norm": 0.11161480098962784,
      "learning_rate": 2.2200888097417307e-05,
      "loss": 0.017,
      "step": 330
    },
    {
      "epoch": 3.0289532293986636,
      "grad_norm": 0.0865587368607521,
      "learning_rate": 2.0658795558326743e-05,
      "loss": 0.012,
      "step": 340
    },
    {
      "epoch": 3.11804008908686,
      "grad_norm": 0.0279145035892725,
      "learning_rate": 1.9133564988307127e-05,
      "loss": 0.0053,
      "step": 350
    },
    {
      "epoch": 3.2071269487750556,
      "grad_norm": 0.04817167669534683,
      "learning_rate": 1.7631120639727393e-05,
      "loss": 0.0067,
      "step": 360
    },
    {
      "epoch": 3.2962138084632517,
      "grad_norm": 0.08384695649147034,
      "learning_rate": 1.6157298259435465e-05,
      "loss": 0.0106,
      "step": 370
    },
    {
      "epoch": 3.3853006681514475,
      "grad_norm": 0.05780033767223358,
      "learning_rate": 1.4717822421734718e-05,
      "loss": 0.0102,
      "step": 380
    },
    {
      "epoch": 3.4743875278396437,
      "grad_norm": 0.07165252417325974,
      "learning_rate": 1.331828429317345e-05,
      "loss": 0.0044,
      "step": 390
    },
    {
      "epoch": 3.5634743875278394,
      "grad_norm": 0.23530441522598267,
      "learning_rate": 1.196411991551255e-05,
      "loss": 0.0063,
      "step": 400
    },
    {
      "epoch": 3.6525612472160356,
      "grad_norm": 0.1250597983598709,
      "learning_rate": 1.0660589091223855e-05,
      "loss": 0.0077,
      "step": 410
    },
    {
      "epoch": 3.7416481069042318,
      "grad_norm": 0.06396832317113876,
      "learning_rate": 9.412754953531663e-06,
      "loss": 0.0053,
      "step": 420
    },
    {
      "epoch": 3.8307349665924275,
      "grad_norm": 0.09288474172353745,
      "learning_rate": 8.225464300350752e-06,
      "loss": 0.0074,
      "step": 430
    },
    {
      "epoch": 3.9198218262806237,
      "grad_norm": 0.04440915212035179,
      "learning_rate": 7.103328768507039e-06,
      "loss": 0.0039,
      "step": 440
    },
    {
      "epoch": 4.008908685968819,
      "grad_norm": 0.021516095846891403,
      "learning_rate": 6.050706921363672e-06,
      "loss": 0.0089,
      "step": 450
    },
    {
      "epoch": 4.097995545657016,
      "grad_norm": 0.014897705987095833,
      "learning_rate": 5.071687319426946e-06,
      "loss": 0.0031,
      "step": 460
    },
    {
      "epoch": 4.187082405345212,
      "grad_norm": 0.06376111507415771,
      "learning_rate": 4.17007263968878e-06,
      "loss": 0.0022,
      "step": 470
    },
    {
      "epoch": 4.276169265033408,
      "grad_norm": 0.052515093237161636,
      "learning_rate": 3.3493649053890326e-06,
      "loss": 0.0017,
      "step": 480
    },
    {
      "epoch": 4.365256124721603,
      "grad_norm": 0.023508258163928986,
      "learning_rate": 2.6127518835674768e-06,
      "loss": 0.0037,
      "step": 490
    },
    {
      "epoch": 4.4543429844097995,
      "grad_norm": 0.03631812334060669,
      "learning_rate": 1.9630947032398067e-06,
      "loss": 0.0024,
      "step": 500
    },
    {
      "epoch": 4.543429844097996,
      "grad_norm": 0.1263800710439682,
      "learning_rate": 1.4029167422908107e-06,
      "loss": 0.0028,
      "step": 510
    },
    {
      "epoch": 4.632516703786192,
      "grad_norm": 0.0789848268032074,
      "learning_rate": 9.343938262496993e-07,
      "loss": 0.0022,
      "step": 520
    },
    {
      "epoch": 4.721603563474387,
      "grad_norm": 0.20843960344791412,
      "learning_rate": 5.593457770173865e-07,
      "loss": 0.0039,
      "step": 530
    },
    {
      "epoch": 4.810690423162583,
      "grad_norm": 0.017111649736762047,
      "learning_rate": 2.7922934437178695e-07,
      "loss": 0.0043,
      "step": 540
    },
    {
      "epoch": 4.8997772828507795,
      "grad_norm": 0.013072166591882706,
      "learning_rate": 9.513254770636137e-08,
      "loss": 0.0072,
      "step": 550
    },
    {
      "epoch": 4.988864142538976,
      "grad_norm": 0.11084882915019989,
      "learning_rate": 7.770449979593864e-09,
      "loss": 0.0022,
      "step": 560
    },
    {
      "epoch": 4.988864142538976,
      "step": 560,
      "total_flos": 1.0223814497282294e+18,
      "train_loss": 0.039045171306601595,
      "train_runtime": 13363.1338,
      "train_samples_per_second": 0.672,
      "train_steps_per_second": 0.042
    }
  ],
  "logging_steps": 10,
  "max_steps": 560,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 3000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0223814497282294e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
