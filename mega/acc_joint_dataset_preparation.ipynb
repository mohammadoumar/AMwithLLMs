{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae3c99e-a531-49c8-afef-57a97b676438",
   "metadata": {},
   "source": [
    "# MEGA DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4530cafd-a236-42a9-8139-6c0be627c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3d113-4224-4362-aa2e-c1a28104d407",
   "metadata": {},
   "source": [
    "## AbstRCT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881db226-fa3d-4183-91ab-ca92b2d7f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aty(x):\n",
    "\n",
    "    x = x.aty\n",
    "    x = x.split(\" \")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f602add-e3aa-4144-8636-50b5c3bfba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_ac_tags(x):\n",
    "\n",
    "    abstract_text = x.abstract_text\n",
    "    acs_list = x.acs_list\n",
    "    ac_types_list = x.ac_types\n",
    "\n",
    "    \n",
    "    # for idx, ac in enumerate(acs_list):\n",
    "    \n",
    "    counter = 1\n",
    "    for idx, (ac, ac_type) in enumerate(zip(acs_list, ac_types_list)):\n",
    "\n",
    "        # if ac != '':\n",
    "        \n",
    "        if ac != '' and ac_type != 'none':\n",
    "\n",
    "            # ac_tags_w_tags = f\"<AC> \" + ac + f\" </AC>\"\n",
    "            \n",
    "            ac_tags_w_tags = f\"\"\"<AC{counter}> \"\"\" + ac + f\"\"\" </AC{counter}>\"\"\" \n",
    "            abstract_text = abstract_text.replace(ac, ac_tags_w_tags) \n",
    "            counter += 1\n",
    "\n",
    "    return abstract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f5edf9-f200-4764-a638-ef8858c3eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(dataset):\n",
    "\n",
    "    rct_df = pd.read_csv(os.path.join(data_dir, dataset))\n",
    "\n",
    "    \n",
    "    abstract_texts_df = rct_df.fillna('').groupby([\"doc_id\"]).agg({\"text\": \"\".join, \"aty\": \" \".join}).reset_index()\n",
    "    abstract_acs_df = rct_df.fillna('').groupby('doc_id')['text'].agg(list).reset_index()\n",
    "    #abstract_ars_df = rct_df.fillna('').groupby('doc_id')['rel_pairs'].agg(list).reset_index()\n",
    "    #abstract_reltypes_df = rct_df.fillna('').groupby('doc_id')['afu'].agg(list).reset_index()\n",
    "    \n",
    "    abstract_texts_df[\"ac_types\"] = abstract_texts_df.apply(lambda x: process_aty(x), axis=1)\n",
    "\n",
    "    abstract_texts_df.rename(columns={'text': 'abstract_text'}, inplace=True)\n",
    "    abstract_texts_df.drop(columns=['aty'], inplace=True)\n",
    "\n",
    "    abstract_acs_df.rename(columns={'text': 'acs_list'}, inplace=True)\n",
    "    \n",
    "    df_merged = pd.merge(abstract_texts_df, abstract_acs_df, on='doc_id')\n",
    "\n",
    "    df_merged[\"tagged_abstract_text\"] = df_merged.apply(lambda x: insert_ac_tags(x), axis=1)\n",
    "\n",
    "    return df_merged    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5959e46b-3cd1-44be-be5e-643445ebe56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"../abstRCT/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86707af-3eea-43a9-8745-0a274e624468",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_train_df = get_dataframe(\"neo/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c37042-e556-49a9-a56b-47a71b755d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo_test_df = get_dataframe(\"neo/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb759343-c855-4b00-ad74-2f9069394a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gla_test_df = get_dataframe(\"gla/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7908517-ee4d-40a1-98fd-6ba6d5abe812",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_test_df = get_dataframe(\"mix/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2120caf5-03e4-4f44-83c3-750ec28f4d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b03ea8a4-206c-4ea9-a30e-f99a8c9c34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_instruction(nr_acs):\n",
    "\n",
    "    results = json.dumps([\"component_type (str)\"] * nr_acs)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length {nr_acs}, in following JSON format: {{\"component_types\": {results}}} where each element \"component_type (str)\" is replaced by either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \n",
    "\"\"\"\n",
    "    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da31430-7c7b-4882-902e-100ffe5ac4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input(abstract_text):\n",
    "    \n",
    "    question = f\"\"\"### Here is the abstract text: {abstract_text}\"\"\"\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98be32c3-7ebc-43bf-a30f-3fc1e7027265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer(ac_types):\n",
    "\n",
    "    ac_types = [label for label in ac_types if label != 'none']\n",
    "    ac_types = ['Claim' if label == 'MajorClaim' else label for label in ac_types]\n",
    "    return json.dumps({\"component_types\": ac_types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db570e8-bf74-4188-950d-152501b12eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_train = []\n",
    "\n",
    "for index, _ in neo_train_df.iterrows():\n",
    "    i = index\n",
    "\n",
    "    instruction = write_instruction(len([ac for ac in neo_train_df.iloc[i].ac_types if ac != 'none']))\n",
    "    question = build_input(neo_train_df.iloc[i].tagged_abstract_text)\n",
    "    answer = build_answer(neo_train_df.iloc[i].ac_types)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05913c74-a851-4fad-8e36-8c2f7df1a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test_neo = []\n",
    "\n",
    "for index, _ in neo_test_df.iterrows():    \n",
    "    i = index\n",
    "    \n",
    "    instruction = write_instruction(len([ac for ac in neo_test_df.iloc[i].ac_types if ac != 'none']))\n",
    "    question = build_input(neo_test_df.iloc[i].tagged_abstract_text)\n",
    "    answer = build_answer(neo_test_df.iloc[i].ac_types)\n",
    "    \n",
    "    data_file_test_neo.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50c83ffa-9060-467e-9ce3-35267e9c11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test_gla = []\n",
    "\n",
    "for index, _ in gla_test_df.iterrows():    \n",
    "    i = index\n",
    "    \n",
    "    instruction = write_instruction(len([ac for ac in gla_test_df.iloc[i].ac_types if ac != 'none']))\n",
    "    question = build_input(gla_test_df.iloc[i].tagged_abstract_text)\n",
    "    answer = build_answer(gla_test_df.iloc[i].ac_types)\n",
    "    \n",
    "    data_file_test_gla.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "169db42c-5c76-49ef-8a9c-3e5eea1bf6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test_mix = []\n",
    "\n",
    "for index, _ in mix_test_df.iterrows():    \n",
    "    i = index\n",
    "    \n",
    "    instruction = write_instruction(len([ac for ac in mix_test_df.iloc[i].ac_types if ac != 'none']))\n",
    "    question = build_input(mix_test_df.iloc[i].tagged_abstract_text)\n",
    "    answer = build_answer(mix_test_df.iloc[i].ac_types)\n",
    "    \n",
    "    data_file_test_mix.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e5feb-5b16-46f6-ad9c-026a40625070",
   "metadata": {},
   "source": [
    "## CDCP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd268c5-65bc-4059-a7c6-cd8a5effa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcp_dataset = load_dataset(\"DFKI-SLT/cdcp\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5d20f-0a44-4a33-ae66-374a08fd4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_instruction(nr_acs):\n",
    "\n",
    "    results = json.dumps([\"component_type (str)\"] * nr_acs)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length {nr_acs}, in following JSON format: {{\"component_types\": {results}}} where each element \"component_type (str)\" is replaced by either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \n",
    "\"\"\"\n",
    "    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b9b883-779d-4811-856a-e15f977963bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cc3327d-830c-444d-828d-60c1f821f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tags(text, start_indices, end_indices):\n",
    "\n",
    "    offset = 0\n",
    "\n",
    "    for i, (start_i, end_i) in enumerate(zip(start_indices, end_indices)):\n",
    "            \n",
    "        start_tag = \"<AC\" + str(i+1) + \">\"\n",
    "        end_tag = \"</AC\" + str(i+1) + \">\"\n",
    "        \n",
    "        start_idx = start_i + offset\n",
    "        end_idx = end_i + offset\n",
    "\n",
    "        offset = offset + (len(start_tag)  + len(end_tag))\n",
    "        \n",
    "        text_r = text[start_idx:end_idx]\n",
    "        new_text = start_tag + text_r + end_tag\n",
    "        text = text.replace(text_r, new_text)\n",
    "\n",
    "        question = f\"\"\"### Here is the text: {text}\"\"\"\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bb87d79-0616-4932-a514-374db1d2d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ac_types(raw_labels):\n",
    "\n",
    "    \n",
    "    class_labels = [\"fact\", \"policy\", \"reference\", \"testimony\", \"value\"]\n",
    "\n",
    "    labels = [class_labels[i] for i in raw_labels]\n",
    "    \n",
    "    return json.dumps({\"component_types\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "338b9406-b38f-49d1-88c5-7e6198fd9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file_train = []\n",
    "\n",
    "for sample in cdcp_dataset[\"train\"]:\n",
    "\n",
    "    sample_text = sample[\"text\"]\n",
    "    start_l = sample[\"propositions\"][\"start\"]\n",
    "    end_l = sample[\"propositions\"][\"end\"]\n",
    "    raw_labels = sample[\"propositions\"][\"label\"]\n",
    "\n",
    "    instruction = write_instruction(len(raw_labels))\n",
    "    question = insert_tags(sample_text, start_l, end_l)\n",
    "    answer = get_ac_types(raw_labels)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22b5772d-672d-482d-b45d-1018e91b65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test_cdcp = []\n",
    "\n",
    "for sample in cdcp_dataset[\"test\"]:\n",
    "\n",
    "    sample_text = sample[\"text\"]\n",
    "    start_l = sample[\"propositions\"][\"start\"]\n",
    "    end_l = sample[\"propositions\"][\"end\"]\n",
    "    raw_labels = sample[\"propositions\"][\"label\"]\n",
    "\n",
    "    instruction = write_instruction(len(raw_labels))\n",
    "    question = insert_tags(sample_text, start_l, end_l)\n",
    "    answer = get_ac_types(raw_labels)\n",
    "    \n",
    "    data_file_test_cdcp.append( formatting_fct(instruction, question, answer) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109758c-3de1-4b20-8bc4-001b7ff9b566",
   "metadata": {},
   "source": [
    "## PE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b0fb17c-1dcd-4fe0-84f4-c10dea987860",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df = pd.read_csv(\"PE_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77c74ca5-29aa-4ed4-82ce-d67811992193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv(\"train-test-split.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cbfe7f0-aef0-49f6-b84d-7fc14254e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df['split'] = pe_df['essay_id'].map(df_split['SET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f02a0b9-e804-46fa-a312-3fb969129857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ac_count(x):\n",
    "\n",
    "    return len(ast.literal_eval(x.AC_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a1fc00c-d28e-46c7-a869-c574f23b7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df[\"AC_count\"] = pe_df.apply(lambda x: get_ac_count(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10e1d4d4-9ae4-4e05-a5b4-48720eaf5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ar_pair_count(x):\n",
    "\n",
    "    return len(ast.literal_eval(x.AR_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bf437d6-a5c9-4e20-b38a-e9173c992c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_df[\"AR_count\"] = pe_df.apply(lambda x: get_ar_pair_count(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc4d0907-1799-4aa0-a40a-463f912fcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df=pe_df.groupby([\"essay_id\", \"split\"]).agg({\"para_text\": \"\".join, \"AC_types\": \"\".join})#.iloc[0][\"AC_types\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006a8969-2377-42ec-a505-0e2fa4db3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df['split'] = [x[1] for x in essays_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5793b4b-e627-4f2f-b9e8-32fbbd8db6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ac_types(x):\n",
    "\n",
    "    x = x.AC_types\n",
    "    x = x.replace(\"[]\", \"\")\n",
    "    x = x.replace(\"][\",\", \") \n",
    "    x = ast.literal_eval(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b39b78b-c5db-49e5-bf56-cf62185ba906",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_df[\"Essay_AC_types\"] = essays_df.apply(lambda x: process_ac_types(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e904cc0-5865-4852-8fe6-6db1df157bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_fct(instruction=\"\", input=\"\", output=\"\", mode=\"train\"):\n",
    "    \n",
    "    prompt_d ={\n",
    "            \n",
    "        \"instruction\": f\"\"\"{instruction}\"\"\",\n",
    "        \"input\": f\"\"\"{input}\"\"\",\n",
    "        \"output\": f\"\"\"{output if mode=='train' else ''}\"\"\"\n",
    "            \n",
    "        }\n",
    "    \n",
    "    return prompt_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3142084-1aed-4c3c-bf7a-3adcbe28c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_instruction(nr_acs):\n",
    "\n",
    "    results = json.dumps([\"component_type (str)\"] * nr_acs)\n",
    "\n",
    "    instruction = f\"\"\"### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length {nr_acs}, in following JSON format: {{\"component_types\": {results}}} where each element \"component_type (str)\" is replaced by either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \n",
    "\"\"\"\n",
    "    \n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d7cbb87-a466-4916-b162-b1be224a5e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_substring_with_position(main_string, substring):\n",
    "    result = \"\"\n",
    "    start = 0\n",
    "    current_index = 0\n",
    "    position = 0  # Initialize position counter\n",
    "    \n",
    "    while current_index < len(main_string):\n",
    "        current_index = main_string.find(substring, current_index)\n",
    "        if current_index == -1:\n",
    "            break\n",
    "        \n",
    "        # Append part of the string before the current match\n",
    "        result += main_string[start:current_index]\n",
    "        \n",
    "        # Append the replacement\n",
    "        sstring = substring[:-1]\n",
    "        # ac_type = ac_types[position]\n",
    "        \n",
    "        result += f\"{sstring}{position+1}>\"\n",
    "        \n",
    "        # Update the start to be the end of the current match\n",
    "        start = current_index + len(substring)\n",
    "        current_index = start\n",
    "        \n",
    "        # Increment the position counter\n",
    "        position += 1\n",
    "    \n",
    "    # Append any remaining part of the string\n",
    "    result += main_string[start:]\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f1d87d6-1d17-458b-9832-0bdc6859d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input(paragraph):\n",
    "    \n",
    "    paragraph = paragraph.replace(\"<prompt> \", \"<topic> \")\n",
    "    paragraph = paragraph.replace(\" </prompt>\", \" </topic>\")\n",
    "    # comment next lines for with paragraph tags\n",
    "    paragraph = paragraph.replace(\"<topic> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </topic>\", \"\")\n",
    "    paragraph = paragraph.replace(\"<para-intro> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </para-intro>\", \"\")\n",
    "    paragraph = paragraph.replace(\"<para-body> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </para-body>\", \"\")\n",
    "    paragraph = paragraph.replace(\"<para-conclusion> \", \"\")\n",
    "    paragraph = paragraph.replace(\" </para-conclusion>\", \"\")\n",
    "    \n",
    "    \n",
    "    paragraph = replace_substring_with_position(paragraph, \"<AC>\")\n",
    "    paragraph = replace_substring_with_position(paragraph, \"</AC>\")\n",
    "\n",
    "    \n",
    "    question = f\"\"\"### Here is the essay text: {paragraph}\"\"\"\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f216206-c55c-4c8c-913b-fd2d4a01a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer(ac_types):\n",
    "\n",
    "    \n",
    "    return json.dumps({\"component_types\": ac_types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3eab1fda-1c1a-4842-bd89-ed81efa0e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>para_text</th>\n",
       "      <th>AC_types</th>\n",
       "      <th>split</th>\n",
       "      <th>Essay_AC_types</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; Should students be taught to compete ...</td>\n",
       "      <td>[]['MajorClaim']['Claim', 'Premise', 'Premise'...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[MajorClaim, Claim, Premise, Premise, Premise,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; More people are migrating to other co...</td>\n",
       "      <td>[]['MajorClaim']['Premise', 'Premise', 'Premis...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Premis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; International tourism is now more com...</td>\n",
       "      <td>[]['MajorClaim']['Premise', 'Premise', 'Premis...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Claim,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>TEST</th>\n",
       "      <td>&lt;prompt&gt; Will newspapers become a thing of the...</td>\n",
       "      <td>[]['MajorClaim']['Premise', 'Premise', 'Premis...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Claim,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>TEST</th>\n",
       "      <td>&lt;prompt&gt; Government budget focus , young child...</td>\n",
       "      <td>[]['MajorClaim']['Premise', 'Premise', 'Premis...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Claim,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <th>TEST</th>\n",
       "      <td>&lt;prompt&gt; The maintenance of traditional skills...</td>\n",
       "      <td>[]['MajorClaim']['Claim', 'Premise', 'Premise'...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>[MajorClaim, Claim, Premise, Premise, Claim, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; University education restriction &lt;/pr...</td>\n",
       "      <td>[][]['Claim', 'Premise', 'Premise', 'Premise']...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[Claim, Premise, Premise, Premise, Premise, Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; Police force carries guns - significa...</td>\n",
       "      <td>[]['MajorClaim']['Premise', 'Premise', 'Premis...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Premise, Premis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; Gun control and increasing violence &lt;...</td>\n",
       "      <td>[]['MajorClaim']['Claim', 'Premise', 'Premise'...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[MajorClaim, Claim, Premise, Premise, Claim, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <th>TRAIN</th>\n",
       "      <td>&lt;prompt&gt; A greater proportion of the budget sh...</td>\n",
       "      <td>[]['MajorClaim']['Premise', 'Premise', 'Claim'...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>[MajorClaim, Premise, Premise, Claim, Premise,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        para_text  \\\n",
       "essay_id split                                                      \n",
       "0        TRAIN  <prompt> Should students be taught to compete ...   \n",
       "1        TRAIN  <prompt> More people are migrating to other co...   \n",
       "2        TRAIN  <prompt> International tourism is now more com...   \n",
       "3        TEST   <prompt> Will newspapers become a thing of the...   \n",
       "4        TEST   <prompt> Government budget focus , young child...   \n",
       "...                                                           ...   \n",
       "397      TEST   <prompt> The maintenance of traditional skills...   \n",
       "398      TRAIN  <prompt> University education restriction </pr...   \n",
       "399      TRAIN  <prompt> Police force carries guns - significa...   \n",
       "400      TRAIN  <prompt> Gun control and increasing violence <...   \n",
       "401      TRAIN  <prompt> A greater proportion of the budget sh...   \n",
       "\n",
       "                                                         AC_types  split  \\\n",
       "essay_id split                                                             \n",
       "0        TRAIN  []['MajorClaim']['Claim', 'Premise', 'Premise'...  TRAIN   \n",
       "1        TRAIN  []['MajorClaim']['Premise', 'Premise', 'Premis...  TRAIN   \n",
       "2        TRAIN  []['MajorClaim']['Premise', 'Premise', 'Premis...  TRAIN   \n",
       "3        TEST   []['MajorClaim']['Premise', 'Premise', 'Premis...   TEST   \n",
       "4        TEST   []['MajorClaim']['Premise', 'Premise', 'Premis...   TEST   \n",
       "...                                                           ...    ...   \n",
       "397      TEST   []['MajorClaim']['Claim', 'Premise', 'Premise'...   TEST   \n",
       "398      TRAIN  [][]['Claim', 'Premise', 'Premise', 'Premise']...  TRAIN   \n",
       "399      TRAIN  []['MajorClaim']['Premise', 'Premise', 'Premis...  TRAIN   \n",
       "400      TRAIN  []['MajorClaim']['Claim', 'Premise', 'Premise'...  TRAIN   \n",
       "401      TRAIN  []['MajorClaim']['Premise', 'Premise', 'Claim'...  TRAIN   \n",
       "\n",
       "                                                   Essay_AC_types  \n",
       "essay_id split                                                     \n",
       "0        TRAIN  [MajorClaim, Claim, Premise, Premise, Premise,...  \n",
       "1        TRAIN  [MajorClaim, Premise, Premise, Premise, Premis...  \n",
       "2        TRAIN  [MajorClaim, Premise, Premise, Premise, Claim,...  \n",
       "3        TEST   [MajorClaim, Premise, Premise, Premise, Claim,...  \n",
       "4        TEST   [MajorClaim, Premise, Premise, Premise, Claim,...  \n",
       "...                                                           ...  \n",
       "397      TEST   [MajorClaim, Claim, Premise, Premise, Claim, P...  \n",
       "398      TRAIN  [Claim, Premise, Premise, Premise, Premise, Cl...  \n",
       "399      TRAIN  [MajorClaim, Premise, Premise, Premise, Premis...  \n",
       "400      TRAIN  [MajorClaim, Claim, Premise, Premise, Claim, P...  \n",
       "401      TRAIN  [MajorClaim, Premise, Premise, Claim, Premise,...  \n",
       "\n",
       "[402 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4630c636-118b-4833-81b0-28f0469eff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file_train = []\n",
    "\n",
    "for index, _ in essays_df[essays_df[\"split\"] == \"TRAIN\"].iterrows():\n",
    "    i = index[0]\n",
    "\n",
    "    instruction = write_instruction(len(essays_df.iloc[i].Essay_AC_types))\n",
    "    question = build_input(essays_df.iloc[i].para_text)\n",
    "    answer = build_answer(essays_df.iloc[i].Essay_AC_types)\n",
    "    \n",
    "    data_file_train.append( formatting_fct(instruction, question, answer, mode=\"train\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df097033-adbc-4775-ac74-2ad47eedaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_test_pe = []\n",
    "\n",
    "for index, _ in essays_df[essays_df.split == \"TEST\"].iterrows():    \n",
    "    i = index[0]\n",
    "\n",
    "    instruction = write_instruction(len(essays_df.iloc[i].Essay_AC_types))\n",
    "    question = build_input(essays_df.iloc[i].para_text)\n",
    "    answer = build_answer(essays_df.iloc[i].Essay_AC_types)\n",
    "    \n",
    "    data_file_test_pe.append( formatting_fct(instruction, question, answer, mode=\"train\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "454349ed-09ce-41fc-a9a9-e17a0a30a998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf7f9126-57cb-4071-87a8-fe499e7771ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 150, 80)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_file_test_neo), len(data_file_test_gla), len(data_file_test_mix), len(data_file_test_cdcp), len(data_file_test_pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fb5d2-7c39-436a-939a-2ab02a4a6c91",
   "metadata": {},
   "source": [
    "## Save JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8ea15a8-f10d-455f-8bd6-67c9bcd8aafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 8, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n',\n",
       " 'input': '### Here is the abstract text:  Single-agent therapy with bicalutamide, a nonsteroidal antiandrogen, was compared with castration, either surgical or medical, in patients with untreated Stage D2 prostate cancer. In an open, randomized, multicenter trial, patients were randomized to treatment with 50 mg bicalutamide (n = 243) once daily or to castration (n = 243), either orchiectomy or depot injection of goserelin acetate every 28 days. Primary efficacy endpoints were times to treatment failure and objective disease progression and survival. Assessments included review of measurable metastases, prostate dimensions, Eastern Cooperative Oncology Group performance status, pain, analgesic requirements, and quality of life responses. The median duration of therapy was 39 weeks for bicalutamide-treated patients and 42 weeks for castrated patients; treatment failure occurred in 53% and 42% and disease progression in 43% and 33%, respectively.<AC1> Treatment effects favored castration for both endpoints (P < or = 0.002), with hazard ratios (bicalutamide:castration) of 1.54 (95% confidence interval [CI], 1.18 to 2.00) for time to treatment failure and 1.6 (95% CI, 1.19 to 2.15) for time to disease progression. </AC1><AC2> From the 1-year survival analysis, the hazard ratio for probability of death was 1.29 (95% CI, 0.96 to 1.72). </AC2><AC3> Thus far, with a median follow-up of 86 weeks, median survival has not been reached in either group. </AC3><AC4> Changes from baseline in several quality of life variables were significantly different (P < or = 0.01) between treatment groups periodically from months 1 to 6, and all favored bicalutamide. </AC4><AC5> Overall, the antiandrogen was well tolerated compared with castration; </AC5><AC6> with bicalutamide, hot flushes occurred less often and breast tenderness and gynecomastia more often. </AC6><AC7> Although a dosage of 50 mg of bicalutamide once daily was not as effective as castration, </AC7><AC8> the favorable quality of life outcomes and the low incidence of nonhormonal adverse events provide reasons to evaluate bicalutamide, as a single therapeutic agent, at higher doses. </AC8>',\n",
       " 'output': '{\"component_types\": [\"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Claim\"]}'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d5d10a1-c1b3-4592-a9db-1428158313ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 14, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n',\n",
       " 'input': '### Here is the text: <AC1>Any collector who uses a robocall, without first having a live person call to verify that the phone number is correct, is lazy and irresponsible.</AC1><AC2> Aside from being a major nuisance, robocalls to a third party are always an improper disclosure </AC2><AC3> because prerecorded calls are required to include the name of the company at the start of the message (per the TCPA).</AC3><AC4> I\\'ve received dozens and dozens of calls like this, </AC4><AC5> and now I know which of my neighbors are alleged to owe money.</AC5><AC6> I say \"alleged\", </AC6><AC7> because the companies making these calls are usually the same scofflaws who have been sued repeatedly for trying to collect nonexistent debts.</AC7><AC8> Outlawing robocalls, particularly robocalls to third parties, would hurt the bad actors without having much impact on legitimate collectors.</AC8><AC9> I wouldn\\'t have a problem with live callers using autodialers, except that the technology used by some collection agencies is so far behind the times.</AC9><AC10> Telemarketers are able to stay within the required 3% abandonment rate,</AC10><AC11> yet my experience is that the drop rate on live calls from collectors ranges from 50% to 100%.</AC11><AC12> Yes, I had one company hang up immediately every single time one of their agents called me. </AC12><AC13> I\\'m not sure how this is profitable.</AC13><AC14> Extending the FTC\\'s 3% rule to debt collection calls would address this issue.</AC14>',\n",
       " 'output': '{\"component_types\": [\"value\", \"value\", \"fact\", \"testimony\", \"testimony\", \"value\", \"fact\", \"value\", \"value\", \"fact\", \"fact\", \"testimony\", \"value\", \"value\"]}'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_train[550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09aed2a4-16e9-4469-b275-73fa2b220e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '### You are an expert in Argument Mining. You are given a text which contains numbered argument components enclosed by <AC></AC> tags. Your task is to classify each argument component in the text as either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". You must return a list of argument component types, strictly of length 12, in following JSON format: {\"component_types\": [\"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\", \"component_type (str)\"]} where each element \"component_type (str)\" is replaced by either \"Major Claim\", \"Claim\", \"Premise\", \"fact\", \"policy\", \"reference\", \"testimony\" or \"value\". \\n',\n",
       " 'input': \"### Here is the essay text: Is it necessary to teach children handwriting ?In this age of modern technology , some people usually underestimate the importance of teaching handwriting for children . To some people , it is considered as an arduous and time consuming task . From my point of view , <AC1> children are those who need to be under instruction of handwriting </AC1> for several reasons .Despite the convenience from up - to - date facilities , <AC2> handwriting still plays a vital role in students ' learning </AC2> . Firstly , <AC3> this approach is a basis tool used in several fields such as taking notes , doing homework and writing </AC3> . <AC4> It enables to improve learners ' spelling capacity and accompany reading or writing disabilities as well </AC4> . <AC5> Under the guidance of parents or teachers , children can benefit from practicing handwriting </AC5> . <AC6> This way of writing will encourage them to pay more attention on content , elaborate in details and develop their organization abilities </AC6> .Secondly , parents and schools should give priority on directing their kids about handwriting as <AC7> poor handwriting can have a negative impact on students ' school performance </AC7> . The fact is that <AC8> kids who are bad at handwriting meet difficulties in taking notes and catching up lessons </AC8> . <AC9> It resulted in the missing of information and the lack of details during their works </AC9> . Moreover , <AC10> the increasing taking advantage of advanced equipment could make students be lazier and more subjective in their writing skills </AC10> . For example , <AC11> with the assistance of automatic grammar and spelling checking in office word , learners are now no need for noticing much in their mistakes </AC11> .To conclude , no matter how fast and convenient modern devices bring to us in writing , <AC12> handwriting is still a needed skill for all of people , especially students at the early age </AC12> .\",\n",
       " 'output': '{\"component_types\": [\"MajorClaim\", \"Claim\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Claim\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"MajorClaim\"]}'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_train[1150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5561c461-2e82-4d09-a1ea-954915c7ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"mega_acc_train.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab3473cb-255d-4b52-89af-59df1e88ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"abstRCT_acc_test_neo.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test_neo, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b8afa9b-6168-45c8-99e1-fb8783fb26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"abstRCT_acc_test_gla.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test_gla, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0befb06d-250d-4eeb-a8fd-7b4beee40fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"abstRCT_acc_test_mix.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test_mix, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36a58abd-ba39-46a8-8e0c-de4940dfd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"CDCP_acc_test.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test_cdcp, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb38fea6-0e67-4cce-833d-08a382b56cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\"PE_ATC_essay_wo_tags_test.json\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    \n",
    "    json.dump(data_file_test_pe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d3f1e-fd70-4984-8376-6e8b8be62fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
